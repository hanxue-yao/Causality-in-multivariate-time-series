{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdb9721c",
   "metadata": {},
   "source": [
    "# case a: test relationship between X_j and Y_k    \n",
    "## yes: if j=k\n",
    "\n",
    "x:10\n",
    "\n",
    "y:10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd7340b",
   "metadata": {},
   "source": [
    "### generate data (synthetic datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b9dc74f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>...</th>\n",
       "      <th>y3</th>\n",
       "      <th>y4</th>\n",
       "      <th>y5</th>\n",
       "      <th>y6</th>\n",
       "      <th>y7</th>\n",
       "      <th>y8</th>\n",
       "      <th>y9</th>\n",
       "      <th>y10</th>\n",
       "      <th>p</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.693071</td>\n",
       "      <td>0.749734</td>\n",
       "      <td>0.740559</td>\n",
       "      <td>0.682252</td>\n",
       "      <td>0.732499</td>\n",
       "      <td>0.738669</td>\n",
       "      <td>0.735497</td>\n",
       "      <td>0.745999</td>\n",
       "      <td>0.686414</td>\n",
       "      <td>0.705529</td>\n",
       "      <td>...</td>\n",
       "      <td>1.315905</td>\n",
       "      <td>1.555777</td>\n",
       "      <td>1.354164</td>\n",
       "      <td>1.354164</td>\n",
       "      <td>1.608329</td>\n",
       "      <td>1.315905</td>\n",
       "      <td>1.272908</td>\n",
       "      <td>1.608329</td>\n",
       "      <td>0.611221</td>\n",
       "      <td>0.768904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.753756</td>\n",
       "      <td>0.731516</td>\n",
       "      <td>0.698611</td>\n",
       "      <td>0.732608</td>\n",
       "      <td>0.722181</td>\n",
       "      <td>0.727579</td>\n",
       "      <td>0.743361</td>\n",
       "      <td>0.727185</td>\n",
       "      <td>0.720573</td>\n",
       "      <td>0.666221</td>\n",
       "      <td>...</td>\n",
       "      <td>1.496442</td>\n",
       "      <td>1.608329</td>\n",
       "      <td>1.315905</td>\n",
       "      <td>1.608329</td>\n",
       "      <td>1.547776</td>\n",
       "      <td>1.268428</td>\n",
       "      <td>1.315905</td>\n",
       "      <td>1.555777</td>\n",
       "      <td>0.387080</td>\n",
       "      <td>0.651297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.714920</td>\n",
       "      <td>0.722104</td>\n",
       "      <td>0.725951</td>\n",
       "      <td>0.730777</td>\n",
       "      <td>0.731724</td>\n",
       "      <td>0.724715</td>\n",
       "      <td>0.676559</td>\n",
       "      <td>0.649171</td>\n",
       "      <td>0.659077</td>\n",
       "      <td>...</td>\n",
       "      <td>1.548994</td>\n",
       "      <td>1.315905</td>\n",
       "      <td>1.547053</td>\n",
       "      <td>1.608329</td>\n",
       "      <td>1.315905</td>\n",
       "      <td>1.221724</td>\n",
       "      <td>1.197032</td>\n",
       "      <td>1.194044</td>\n",
       "      <td>0.301979</td>\n",
       "      <td>0.569107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.629484</td>\n",
       "      <td>0.664594</td>\n",
       "      <td>0.694678</td>\n",
       "      <td>0.735082</td>\n",
       "      <td>0.648595</td>\n",
       "      <td>0.727943</td>\n",
       "      <td>0.719407</td>\n",
       "      <td>0.687940</td>\n",
       "      <td>0.672185</td>\n",
       "      <td>0.742846</td>\n",
       "      <td>...</td>\n",
       "      <td>1.216047</td>\n",
       "      <td>1.255770</td>\n",
       "      <td>1.249525</td>\n",
       "      <td>1.608329</td>\n",
       "      <td>1.608329</td>\n",
       "      <td>1.272908</td>\n",
       "      <td>1.527197</td>\n",
       "      <td>1.260424</td>\n",
       "      <td>0.275765</td>\n",
       "      <td>0.502619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.727027</td>\n",
       "      <td>0.659385</td>\n",
       "      <td>0.626638</td>\n",
       "      <td>0.731164</td>\n",
       "      <td>0.639826</td>\n",
       "      <td>0.641906</td>\n",
       "      <td>0.670579</td>\n",
       "      <td>0.671552</td>\n",
       "      <td>0.679148</td>\n",
       "      <td>0.702513</td>\n",
       "      <td>...</td>\n",
       "      <td>1.489547</td>\n",
       "      <td>1.608329</td>\n",
       "      <td>1.444886</td>\n",
       "      <td>1.218720</td>\n",
       "      <td>1.491336</td>\n",
       "      <td>1.480879</td>\n",
       "      <td>1.272908</td>\n",
       "      <td>1.496992</td>\n",
       "      <td>0.260415</td>\n",
       "      <td>0.455732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.524838</td>\n",
       "      <td>0.516246</td>\n",
       "      <td>0.517053</td>\n",
       "      <td>0.521333</td>\n",
       "      <td>0.499947</td>\n",
       "      <td>0.519173</td>\n",
       "      <td>0.497044</td>\n",
       "      <td>0.519600</td>\n",
       "      <td>0.528204</td>\n",
       "      <td>0.526396</td>\n",
       "      <td>...</td>\n",
       "      <td>1.258192</td>\n",
       "      <td>1.024750</td>\n",
       "      <td>1.258418</td>\n",
       "      <td>1.256844</td>\n",
       "      <td>1.028856</td>\n",
       "      <td>1.033939</td>\n",
       "      <td>1.252952</td>\n",
       "      <td>1.029195</td>\n",
       "      <td>-0.022146</td>\n",
       "      <td>0.074694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.517562</td>\n",
       "      <td>0.512992</td>\n",
       "      <td>0.495451</td>\n",
       "      <td>0.518186</td>\n",
       "      <td>0.523072</td>\n",
       "      <td>0.520441</td>\n",
       "      <td>0.521268</td>\n",
       "      <td>0.515206</td>\n",
       "      <td>0.518452</td>\n",
       "      <td>0.520581</td>\n",
       "      <td>...</td>\n",
       "      <td>1.257288</td>\n",
       "      <td>1.032519</td>\n",
       "      <td>1.024057</td>\n",
       "      <td>1.258584</td>\n",
       "      <td>1.260589</td>\n",
       "      <td>1.260605</td>\n",
       "      <td>1.260384</td>\n",
       "      <td>1.031817</td>\n",
       "      <td>-0.006050</td>\n",
       "      <td>0.082098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.505270</td>\n",
       "      <td>0.510909</td>\n",
       "      <td>0.523240</td>\n",
       "      <td>0.511838</td>\n",
       "      <td>0.527147</td>\n",
       "      <td>0.511199</td>\n",
       "      <td>0.508021</td>\n",
       "      <td>0.531374</td>\n",
       "      <td>0.503130</td>\n",
       "      <td>0.530990</td>\n",
       "      <td>...</td>\n",
       "      <td>1.032274</td>\n",
       "      <td>1.259927</td>\n",
       "      <td>1.029615</td>\n",
       "      <td>1.257242</td>\n",
       "      <td>1.031171</td>\n",
       "      <td>1.261795</td>\n",
       "      <td>1.032017</td>\n",
       "      <td>1.261315</td>\n",
       "      <td>0.188805</td>\n",
       "      <td>0.083666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.510129</td>\n",
       "      <td>0.514223</td>\n",
       "      <td>0.521072</td>\n",
       "      <td>0.516532</td>\n",
       "      <td>0.533470</td>\n",
       "      <td>0.538032</td>\n",
       "      <td>0.512905</td>\n",
       "      <td>0.499889</td>\n",
       "      <td>0.524074</td>\n",
       "      <td>0.534286</td>\n",
       "      <td>...</td>\n",
       "      <td>1.032626</td>\n",
       "      <td>1.262770</td>\n",
       "      <td>1.029016</td>\n",
       "      <td>1.031041</td>\n",
       "      <td>1.033162</td>\n",
       "      <td>1.260108</td>\n",
       "      <td>1.032569</td>\n",
       "      <td>1.261110</td>\n",
       "      <td>0.079071</td>\n",
       "      <td>0.081430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.515339</td>\n",
       "      <td>0.514199</td>\n",
       "      <td>0.525498</td>\n",
       "      <td>0.514060</td>\n",
       "      <td>0.510722</td>\n",
       "      <td>0.520147</td>\n",
       "      <td>0.512437</td>\n",
       "      <td>0.527516</td>\n",
       "      <td>0.507805</td>\n",
       "      <td>0.529540</td>\n",
       "      <td>...</td>\n",
       "      <td>1.034502</td>\n",
       "      <td>1.033699</td>\n",
       "      <td>1.028514</td>\n",
       "      <td>1.267485</td>\n",
       "      <td>1.025627</td>\n",
       "      <td>1.030817</td>\n",
       "      <td>1.261614</td>\n",
       "      <td>1.035054</td>\n",
       "      <td>-0.036881</td>\n",
       "      <td>0.088152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           x1        x2        x3        x4        x5        x6        x7  \\\n",
       "0    0.693071  0.749734  0.740559  0.682252  0.732499  0.738669  0.735497   \n",
       "1    0.753756  0.731516  0.698611  0.732608  0.722181  0.727579  0.743361   \n",
       "2    0.718531  0.714920  0.722104  0.725951  0.730777  0.731724  0.724715   \n",
       "3    0.629484  0.664594  0.694678  0.735082  0.648595  0.727943  0.719407   \n",
       "4    0.727027  0.659385  0.626638  0.731164  0.639826  0.641906  0.670579   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "995  0.524838  0.516246  0.517053  0.521333  0.499947  0.519173  0.497044   \n",
       "996  0.517562  0.512992  0.495451  0.518186  0.523072  0.520441  0.521268   \n",
       "997  0.505270  0.510909  0.523240  0.511838  0.527147  0.511199  0.508021   \n",
       "998  0.510129  0.514223  0.521072  0.516532  0.533470  0.538032  0.512905   \n",
       "999  0.515339  0.514199  0.525498  0.514060  0.510722  0.520147  0.512437   \n",
       "\n",
       "           x8        x9       x10  ...        y3        y4        y5  \\\n",
       "0    0.745999  0.686414  0.705529  ...  1.315905  1.555777  1.354164   \n",
       "1    0.727185  0.720573  0.666221  ...  1.496442  1.608329  1.315905   \n",
       "2    0.676559  0.649171  0.659077  ...  1.548994  1.315905  1.547053   \n",
       "3    0.687940  0.672185  0.742846  ...  1.216047  1.255770  1.249525   \n",
       "4    0.671552  0.679148  0.702513  ...  1.489547  1.608329  1.444886   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "995  0.519600  0.528204  0.526396  ...  1.258192  1.024750  1.258418   \n",
       "996  0.515206  0.518452  0.520581  ...  1.257288  1.032519  1.024057   \n",
       "997  0.531374  0.503130  0.530990  ...  1.032274  1.259927  1.029615   \n",
       "998  0.499889  0.524074  0.534286  ...  1.032626  1.262770  1.029016   \n",
       "999  0.527516  0.507805  0.529540  ...  1.034502  1.033699  1.028514   \n",
       "\n",
       "           y6        y7        y8        y9       y10         p         z  \n",
       "0    1.354164  1.608329  1.315905  1.272908  1.608329  0.611221  0.768904  \n",
       "1    1.608329  1.547776  1.268428  1.315905  1.555777  0.387080  0.651297  \n",
       "2    1.608329  1.315905  1.221724  1.197032  1.194044  0.301979  0.569107  \n",
       "3    1.608329  1.608329  1.272908  1.527197  1.260424  0.275765  0.502619  \n",
       "4    1.218720  1.491336  1.480879  1.272908  1.496992  0.260415  0.455732  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "995  1.256844  1.028856  1.033939  1.252952  1.029195 -0.022146  0.074694  \n",
       "996  1.258584  1.260589  1.260605  1.260384  1.031817 -0.006050  0.082098  \n",
       "997  1.257242  1.031171  1.261795  1.032017  1.261315  0.188805  0.083666  \n",
       "998  1.031041  1.033162  1.260108  1.032569  1.261110  0.079071  0.081430  \n",
       "999  1.267485  1.025627  1.030817  1.261614  1.035054 -0.036881  0.088152  \n",
       "\n",
       "[1000 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "\n",
    "total_length=1000\n",
    "\n",
    "def sigmoid(x):\n",
    "        return 1 / (1 + math.exp(-x))\n",
    "    \n",
    "def generate(sig_to_noise): \n",
    "    np.random.seed(0)\n",
    "    z = [1,1,1,1]\n",
    "    x_arr = np.full((10,4),1.0)\n",
    "    y_arr = np.full((10,4),3.0)\n",
    "    x_arr_unini = np.full((10,total_length),0.0)\n",
    "    y_arr_unini = np.full((10,total_length),0.0)\n",
    "    x = np.hstack((x_arr, x_arr_unini))\n",
    "    y = np.hstack((y_arr, y_arr_unini)) \n",
    "    \n",
    "    p = []\n",
    "    n = [3,3,3,3]\n",
    "    t1 = [3,3,3,3]\n",
    "    \n",
    "    \n",
    "    for i in range(4,total_length+4):  #time\n",
    "        z.append(math.tanh(z[i-1]+np.random.normal(0,0.01)))\n",
    "        p.append(z[i]**2+np.random.normal(0,0.05))\n",
    "        \n",
    "        for j in range(0,10):\n",
    "            m = random.randint(1,5)  #random lag\n",
    "            n = random.randint(1,5)  #random lag\n",
    "            x[j][i] = sigmoid(z[i-m])+np.random.normal(0,0.01)\n",
    "            term1 = sigmoid(z[i-m])\n",
    "            term2 = sigmoid(x[j][i-n])\n",
    "            noise = np.random.normal(0,1)\n",
    "            alpha = (abs(term1+term2)/sig_to_noise)/abs(noise)\n",
    "            \n",
    "            y[j][i] = term1+term2+alpha*noise\n",
    "\n",
    "\n",
    "    x=x[:,-total_length:]    \n",
    "    y=y[:,-total_length:]\n",
    "    p=p[-total_length:]\n",
    "    z=z[-total_length:]\n",
    "    \n",
    "    #add x1 and y1 into dataframe\n",
    "    #table format 1\n",
    "    df1=pd.DataFrame({\"x1\":x[0,:]})\n",
    "    for m in range(1,10):\n",
    "        df1.insert(loc=len(df1.columns), column='x'+str(m+1), value=x[m,:])\n",
    "    for m in range(0,10):\n",
    "        df1.insert(loc=len(df1.columns), column='y'+str(m+1), value=y[m,:])\n",
    "    df1.insert(loc=len(df1.columns), column='p', value=p)\n",
    "    df1.insert(loc=len(df1.columns), column='z', value=z)\n",
    "    \n",
    "    '''\n",
    "    #table format 2\n",
    "    df1=pd.DataFrame({\"x1\":x[0,:],\"y1\":y[0,:]})\n",
    "    for k in range(1,10):\n",
    "        df1.insert(loc=len(df1.columns), column='x'+str(k+1), value=x[k,:])    \n",
    "        df1.insert(loc=len(df1.columns), column='y'+str(k+1), value=y[k,:])\n",
    "        \n",
    "    df1.insert(loc=len(df1.columns), column='p', value=p)\n",
    "    df1.insert(loc=len(df1.columns), column='z', value=z)\n",
    "    '''\n",
    "    return df1\n",
    "\n",
    "df1 = generate(10)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "effed234",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(\"case_a.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7575182",
   "metadata": {},
   "source": [
    "# main 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e7ba53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaohanxue/Desktop/hx_model/data_loader.py:46: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:198.)\n",
      "  return torch.tensor(x), torch.tensor(y)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-0ba61ff490d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m full_mses, full_mses_res = obtain_errors(model, 50, train_loader,\\\n\u001b[1;32m     59\u001b[0m                           val_loader, test_loader, scaler)  \n",
      "\u001b[0;32m<ipython-input-7-0ba61ff490d6>\u001b[0m in \u001b[0;36mrun_model\u001b[0;34m(z, p, x, y, seq)\u001b[0m\n\u001b[1;32m     51\u001b[0m                             \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                             test_loader, scaler, lr=0.001, lam=0.01)\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvae_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/hx_model/train.py\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(self, epochs)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_val_test_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvmse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvmse_nox\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_val_test_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"val\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmse_nox\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_val_test_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/hx_model/train.py\u001b[0m in \u001b[0;36mtrain_val_test_iter\u001b[0;34m(self, d, mode, res)\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmse_nox\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moperate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/hx_model/train.py\u001b[0m in \u001b[0;36moperate\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"full\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz_prior\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz_post\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_hats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                             \u001b[0my_hats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp_hats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_nox_hats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m\"No\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1129\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1130\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1131\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1132\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/hx_model/gruvae.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, y, p, x, res)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"No\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mzs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_prior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_post\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_z\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_hats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0my_hats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_hats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_nox_hats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_GRUVAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mzs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_prior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_post\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_z\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_hats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_hats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_hats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_nox_hats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/hx_model/gruvae.py\u001b[0m in \u001b[0;36mrun_GRUVAE\u001b[0;34m(self, y, p, x, res)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru_z_post\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mg_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru_z_post\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0mh_z_prev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru_z_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \"multiprocessing, you must use the 'spawn' start method\")\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cuda_getDeviceCount'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             raise AssertionError(\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from torch import optim\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "\n",
    "#os.chdir(\"C:/Users/tonyz/Desktop/Granger/model\")\n",
    "import gruvae\n",
    "import train\n",
    "from data_loader import create_inout_sequences\n",
    "from functions import t_test\n",
    "from generate_data_a import generate\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"case_a.csv\")[:1000]\n",
    "\n",
    "k=random.randint(0, 9)\n",
    "l=random.randint(0, 9)\n",
    "\n",
    "x = data['x'+str(k+1)].tolist()\n",
    "y = data['y'+str(l+1)].tolist()\n",
    "z = data[\"z\"].tolist()\n",
    "p = data[\"p\"].tolist()\n",
    "\n",
    "\n",
    "  \n",
    "def obtain_errors(model,trials, train_loader,\\\n",
    "                  val_loader, test_loader, scaler, lam=0,\\\n",
    "                  model_type=\"full\", res=\"No\"):\n",
    "    torch.manual_seed(0)\n",
    "    mses = []\n",
    "    mses_nox = []\n",
    "    vae_trainer = train.AutoEncoderTrainer(model, optim.Adam,\\\n",
    "                    train_loader, val_loader,\\\n",
    "                    test_loader, scaler, 0.001, lam, model_type)\n",
    "    for i in range(trials):\n",
    "        _,mse,mse_nox,_ = vae_trainer.train_val_test_iter(test_loader,\\\n",
    "                                                          \"test\", res)\n",
    "        mses.append(mse)\n",
    "        mses_nox.append(mse_nox)\n",
    "    return mses,mses_nox\n",
    "\n",
    "\n",
    "def run_model(z, p, x, y, seq=20):\n",
    "    torch.manual_seed(0)\n",
    "    model=gruvae.GRUVAE(1,1,5,5,5,5,2,5,10,3,0.3)\n",
    "    train_loader, val_loader, test_loader, scaler\\\n",
    "        = create_inout_sequences(z, p, x, y, seq, 800, 100, 100, 10)\n",
    "    vae_trainer = train.AutoEncoderTrainer(model, optim.Adam,\\\n",
    "                            train_loader, val_loader,\\\n",
    "                            test_loader, scaler, lr=0.001, lam=0.01)\n",
    "    _,_,model = vae_trainer.train_and_evaluate(50)\n",
    "    return train_loader, val_loader, test_loader, model, scaler\n",
    "\n",
    "\n",
    "train_loader, val_loader, test_loader, model, scaler = run_model(z, p, x, y)\n",
    "full_mses, full_mses_res = obtain_errors(model, 50, train_loader,\\\n",
    "                          val_loader, test_loader, scaler)  \n",
    "        \n",
    "print(t_test([i.tolist() for i in full_mses],\\\n",
    "             [i.tolist() for i in full_mses_res],alternative='greater'))\n",
    "             \n",
    "def calc_pvalues(sig_to_noise_low=\"default\", sig_to_noise_upp=\"default\"):\n",
    "    \n",
    "    if sig_to_noise_low !=\"default\":\n",
    "        data_low = generate(sig_to_noise_low)\n",
    "        z_low = data_low[\"z\"].tolist()\n",
    "        p_low = data_low[\"p\"].tolist()\n",
    "        x_low = data_low[\"x\"].tolist()\n",
    "        y_low = data_low[\"y\"].tolist()\n",
    "        \n",
    "        train_loader, val_loader, test_loader, model, scaler\\\n",
    "            = run_model(z_low, p_low, x_low, y_low)\n",
    "        full_mses, full_mses_res = obtain_errors(model, 50, train_loader,\\\n",
    "            val_loader, test_loader, scaler)  \n",
    "        p_value_low = t_test([i.tolist() for i in full_mses],\\\n",
    "            [i.tolist() for i in full_mses_res],alternative='less')\n",
    "    \n",
    "    if sig_to_noise_upp !=\"default\":\n",
    "        data_upp = generate(sig_to_noise_upp)\n",
    "        z_upp = data_upp[\"z\"].tolist()\n",
    "        p_upp = data_upp[\"p\"].tolist()\n",
    "        x_upp = data_upp[\"x\"].tolist()\n",
    "        y_upp = data_upp[\"y\"].tolist()\n",
    "   \n",
    "        train_loader, val_loader, test_loader, model, scaler\\\n",
    "            = run_model(z_upp, p_upp, x_upp, y_upp)\n",
    "        full_mses, full_mses_res = obtain_errors(model, 50, train_loader,\\\n",
    "            val_loader, test_loader, scaler)  \n",
    "        p_value_upp = t_test([i.tolist() for i in full_mses],\\\n",
    "            [i.tolist() for i in full_mses_res],alternative='less')\n",
    "    \n",
    "    if  sig_to_noise_low!=\"default\" and sig_to_noise_upp!=\"default\":   \n",
    "        return p_value_low, p_value_upp\n",
    "    elif sig_to_noise_low!=\"default\" and sig_to_noise_upp==\"default\":\n",
    "        return p_value_low\n",
    "    elif sig_to_noise_upp!=\"default\" and sig_to_noise_low==\"default\":\n",
    "        return p_value_upp\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    \n",
    "def vary_alpha(trials, sig_to_noise_low, sig_to_noise_upp, type=\"bisection\",\\\n",
    "               step=0.1):\n",
    "    p_value_low, p_value_upp = calc_pvalues(sig_to_noise_low,sig_to_noise_upp)    \n",
    "    print(p_value_low, p_value_upp)\n",
    "    \n",
    "    if p_value_low<0.05 and p_value_upp<0.05:\n",
    "        print(\"enter new bounds\")\n",
    "        return None\n",
    "    elif p_value_low>0.05 and p_value_upp>0.05:\n",
    "        print(\"enter new bounds\")\n",
    "        return None\n",
    "    c=0\n",
    "    if type==\"bisection\":\n",
    "        prev_low = 0\n",
    "        prev_p = 0\n",
    "        for i in range(trials):\n",
    "            print(f\"\\tsig_to_noise_low: {sig_to_noise_low}, p_low: {p_value_low}, sig_to_noise_upp: {sig_to_noise_upp}, p_upp: {p_value_upp}\")            \n",
    "            prev_low = sig_to_noise_low\n",
    "            prev_p = p_value_low\n",
    "            if p_value_low>0.05:\n",
    "                sig_to_noise_low = (sig_to_noise_upp+sig_to_noise_low)/2\n",
    "                p_value_low = calc_pvalues(sig_to_noise_low=sig_to_noise_low)\n",
    "            if p_value_low<0.05:\n",
    "                sig_to_noise_upp = sig_to_noise_low\n",
    "                sig_to_noise_low = prev_low\n",
    "                p_value_upp = p_value_low\n",
    "                p_value_low = prev_p\n",
    "    else:\n",
    "        while c==0:\n",
    "            sig_to_noise_low+=step\n",
    "            p_value_low = calc_pvalues(sig_to_noise_low=sig_to_noise_low)\n",
    "            print(f\"\\tsig_to_noise_low: {sig_to_noise_low}, p_low: {p_value_low}, sig_to_noise_upp: {sig_to_noise_upp}, p_upp: {p_value_upp}\")\n",
    "            if p_value_low<0.05:       \n",
    "                break\n",
    "\n",
    "\n",
    "def vary_seq(seqs, z, p, x, y):\n",
    "    for i in seqs:\n",
    "        train_loader, val_loader, test_loader, model, scaler\\\n",
    "            = run_model(z, p, x, y, i)\n",
    "        full_mses, full_mses_res = obtain_errors(model, 50, train_loader,\\\n",
    "                          val_loader, test_loader, scaler) \n",
    "        p_val = t_test([i.tolist() for i in full_mses],\\\n",
    "             [i.tolist() for i in full_mses_res],alternative='less')  \n",
    "        print(f\"\\tlength: {i}, p_val: {p_val}\")\n",
    "\n",
    "'''\n",
    "if __name__==\"__main__\":\n",
    "    #vary_alpha(1,5, type=\"e\", step=1)\n",
    "    #vary_alpha(3,4, type=\"e\", step=0.1)\n",
    "    #vary_alpha(3,3.1, type=\"e\", step=0.01) #3.05\n",
    "    \n",
    "    #vary_alpha(8,0.5,10)\n",
    "    vary_seq([4,6,8,10,12,14,16], z, p, x, y)\n",
    "'''   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e4ac86",
   "metadata": {},
   "source": [
    "# main 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822fa3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from torch import optim\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "\n",
    "#os.chdir(\"C:/Users/tonyz/Desktop/Granger/model\")\n",
    "import gruvae\n",
    "import train\n",
    "from data_loader import create_inout_sequences\n",
    "from functions import t_test\n",
    "from generate_data_a import generate\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"case_a.csv\")[:1000]\n",
    "\n",
    "k=random.randint(0, 9)\n",
    "l=random.randint(0, 9)\n",
    "\n",
    "x = data['x'+str(k+1)].tolist()\n",
    "y = data['y'+str(l+1)].tolist()\n",
    "z = data[\"z\"].tolist()\n",
    "\n",
    "data = data.iloc[: , 1:]\n",
    "p1 = data[data.columns.difference(['x'+str(k+1), 'y'+str(l+1), \"z\"])].values.tolist()\n",
    "\n",
    "\n",
    "  \n",
    "def obtain_errors(model,trials, train_loader,\\\n",
    "                  val_loader, test_loader, scaler, lam=0,\\\n",
    "                  model_type=\"full\", res=\"No\"):\n",
    "    torch.manual_seed(0)\n",
    "    mses = []\n",
    "    mses_nox = []\n",
    "    vae_trainer = train.AutoEncoderTrainer(model, optim.Adam,\\\n",
    "                    train_loader, val_loader,\\\n",
    "                    test_loader, scaler, 0.001, lam, model_type)\n",
    "    for i in range(trials):\n",
    "        _,mse,mse_nox,_ = vae_trainer.train_val_test_iter(test_loader,\\\n",
    "                                                          \"test\", res)\n",
    "        mses.append(mse)\n",
    "        mses_nox.append(mse_nox)\n",
    "    return mses,mses_nox\n",
    "\n",
    "\n",
    "def run_model(z, p1, x, y, seq=20):\n",
    "    torch.manual_seed(0)\n",
    "    model=gruvae.GRUVAE(1,1,5,5,5,5,2,5,10,3,0.3)\n",
    "    train_loader, val_loader, test_loader, scaler\\\n",
    "        = create_inout_sequences(z, p1, x, y, seq, 800, 100, 100, 10)\n",
    "    vae_trainer = train.AutoEncoderTrainer(model, optim.Adam,\\\n",
    "                            train_loader, val_loader,\\\n",
    "                            test_loader, scaler, lr=0.001, lam=0.01)\n",
    "    _,_,model = vae_trainer.train_and_evaluate(50)\n",
    "    return train_loader, val_loader, test_loader, model, scaler\n",
    "\n",
    "\n",
    "train_loader, val_loader, test_loader, model, scaler = run_model(z, p1, x, y)\n",
    "full_mses, full_mses_res = obtain_errors(model, 50, train_loader,\\\n",
    "                          val_loader, test_loader, scaler)  \n",
    "        \n",
    "print(t_test([i.tolist() for i in full_mses],\\\n",
    "             [i.tolist() for i in full_mses_res],alternative='greater'))\n",
    "             \n",
    "def calc_pvalues(sig_to_noise_low=\"default\", sig_to_noise_upp=\"default\"):\n",
    "    \n",
    "    if sig_to_noise_low !=\"default\":\n",
    "        data_low = generate(sig_to_noise_low)\n",
    "        z_low = data_low[\"z\"].tolist()\n",
    "        p_low = data_low[\"p1\"].tolist()\n",
    "        x_low = data_low[\"x\"].tolist()\n",
    "        y_low = data_low[\"y\"].tolist()\n",
    "        \n",
    "        train_loader, val_loader, test_loader, model, scaler\\\n",
    "            = run_model(z_low, p_low, x_low, y_low)\n",
    "        full_mses, full_mses_res = obtain_errors(model, 50, train_loader,\\\n",
    "            val_loader, test_loader, scaler)  \n",
    "        p_value_low = t_test([i.tolist() for i in full_mses],\\\n",
    "            [i.tolist() for i in full_mses_res],alternative='less')\n",
    "    \n",
    "    if sig_to_noise_upp !=\"default\":\n",
    "        data_upp = generate(sig_to_noise_upp)\n",
    "        z_upp = data_upp[\"z\"].tolist()\n",
    "        p_upp = data_upp[\"p1\"].tolist()\n",
    "        x_upp = data_upp[\"x\"].tolist()\n",
    "        y_upp = data_upp[\"y\"].tolist()\n",
    "   \n",
    "        train_loader, val_loader, test_loader, model, scaler\\\n",
    "            = run_model(z_upp, p_upp, x_upp, y_upp)\n",
    "        full_mses, full_mses_res = obtain_errors(model, 50, train_loader,\\\n",
    "            val_loader, test_loader, scaler)  \n",
    "        p_value_upp = t_test([i.tolist() for i in full_mses],\\\n",
    "            [i.tolist() for i in full_mses_res],alternative='less')\n",
    "    \n",
    "    if  sig_to_noise_low!=\"default\" and sig_to_noise_upp!=\"default\":   \n",
    "        return p_value_low, p_value_upp\n",
    "    elif sig_to_noise_low!=\"default\" and sig_to_noise_upp==\"default\":\n",
    "        return p_value_low\n",
    "    elif sig_to_noise_upp!=\"default\" and sig_to_noise_low==\"default\":\n",
    "        return p_value_upp\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    \n",
    "def vary_alpha(trials, sig_to_noise_low, sig_to_noise_upp, type=\"bisection\",\\\n",
    "               step=0.1):\n",
    "    p_value_low, p_value_upp = calc_pvalues(sig_to_noise_low,sig_to_noise_upp)    \n",
    "    print(p_value_low, p_value_upp)\n",
    "    \n",
    "    if p_value_low<0.05 and p_value_upp<0.05:\n",
    "        print(\"enter new bounds\")\n",
    "        return None\n",
    "    elif p_value_low>0.05 and p_value_upp>0.05:\n",
    "        print(\"enter new bounds\")\n",
    "        return None\n",
    "    c=0\n",
    "    if type==\"bisection\":\n",
    "        prev_low = 0\n",
    "        prev_p = 0\n",
    "        for i in range(trials):\n",
    "            print(f\"\\tsig_to_noise_low: {sig_to_noise_low}, p_low: {p_value_low}, sig_to_noise_upp: {sig_to_noise_upp}, p_upp: {p_value_upp}\")            \n",
    "            prev_low = sig_to_noise_low\n",
    "            prev_p = p_value_low\n",
    "            if p_value_low>0.05:\n",
    "                sig_to_noise_low = (sig_to_noise_upp+sig_to_noise_low)/2\n",
    "                p_value_low = calc_pvalues(sig_to_noise_low=sig_to_noise_low)\n",
    "            if p_value_low<0.05:\n",
    "                sig_to_noise_upp = sig_to_noise_low\n",
    "                sig_to_noise_low = prev_low\n",
    "                p_value_upp = p_value_low\n",
    "                p_value_low = prev_p\n",
    "    else:\n",
    "        while c==0:\n",
    "            sig_to_noise_low+=step\n",
    "            p_value_low = calc_pvalues(sig_to_noise_low=sig_to_noise_low)\n",
    "            print(f\"\\tsig_to_noise_low: {sig_to_noise_low}, p_low: {p_value_low}, sig_to_noise_upp: {sig_to_noise_upp}, p_upp: {p_value_upp}\")\n",
    "            if p_value_low<0.05:       \n",
    "                break\n",
    "\n",
    "\n",
    "def vary_seq(seqs, z, p1, x, y):\n",
    "    for i in seqs:\n",
    "        train_loader, val_loader, test_loader, model, scaler\\\n",
    "            = run_model(z, p1, x, y, i)\n",
    "        full_mses, full_mses_res = obtain_errors(model, 50, train_loader,\\\n",
    "                          val_loader, test_loader, scaler) \n",
    "        p_val = t_test([i.tolist() for i in full_mses],\\\n",
    "             [i.tolist() for i in full_mses_res],alternative='less')  \n",
    "        print(f\"\\tlength: {i}, p_val: {p_val}\")\n",
    "\n",
    "'''\n",
    "if __name__==\"__main__\":\n",
    "    #vary_alpha(1,5, type=\"e\", step=1)\n",
    "    #vary_alpha(3,4, type=\"e\", step=0.1)\n",
    "    #vary_alpha(3,3.1, type=\"e\", step=0.01) #3.05\n",
    "    \n",
    "    #vary_alpha(8,0.5,10)\n",
    "    vary_seq([4,6,8,10,12,14,16], z, p1, x, y)\n",
    "'''   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8519b654",
   "metadata": {},
   "source": [
    "# main 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efef884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from torch import optim\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import pandas as pd  # to load the dataframe\n",
    "from sklearn.preprocessing import StandardScaler  # to standardize the features\n",
    "from sklearn.decomposition import PCA  # to apply PCA\n",
    "\n",
    "\n",
    "#os.chdir(\"C:/Users/tonyz/Desktop/Granger/model\")\n",
    "import gruvae\n",
    "import train\n",
    "from data_loader import create_inout_sequences\n",
    "from functions import t_test\n",
    "from generate_data_a import generate\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"case_a.csv\")[:1000]\n",
    "\n",
    "k=random.randint(0, 9)\n",
    "l=random.randint(0, 9)\n",
    "\n",
    "x = data['x'+str(k+1)].tolist()\n",
    "y = data['y'+str(l+1)].tolist()\n",
    "z = data[\"z\"].tolist()\n",
    "\n",
    "data = data.iloc[: , 1:]\n",
    "p1 = data[data.columns.difference(['x'+str(k+1), 'y'+str(l+1), \"z\"])]\n",
    "\n",
    "#PCA\n",
    "#convert the dataset into a pandas data frame\n",
    "df = pd.DataFrame(p1)\n",
    "\n",
    "#Standardize the features\n",
    "#Create an object of StandardScaler which is present in sklearn.preprocessing\n",
    "scalar = StandardScaler()\n",
    "scaled_data = pd.DataFrame(scalar.fit_transform(df), columns=df.columns) #scaling the data\n",
    "\n",
    "#Applying PCA\n",
    "#Taking no. of Principal Components as 1\n",
    "pca = PCA(n_components = 1)\n",
    "pca.fit(scaled_data)\n",
    "data_pca = pca.transform(scaled_data)\n",
    "data_pca = pd.DataFrame(data_pca,columns=['PC1'])\n",
    "p2 = data_pca['PC1'].tolist()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "def obtain_errors(model,trials, train_loader,\\\n",
    "                  val_loader, test_loader, scaler, lam=0,\\\n",
    "                  model_type=\"full\", res=\"No\"):\n",
    "    torch.manual_seed(0)\n",
    "    mses = []\n",
    "    mses_nox = []\n",
    "    vae_trainer = train.AutoEncoderTrainer(model, optim.Adam,\\\n",
    "                    train_loader, val_loader,\\\n",
    "                    test_loader, scaler, 0.001, lam, model_type)\n",
    "    for i in range(trials):\n",
    "        _,mse,mse_nox,_ = vae_trainer.train_val_test_iter(test_loader,\\\n",
    "                                                          \"test\", res)\n",
    "        mses.append(mse)\n",
    "        mses_nox.append(mse_nox)\n",
    "    return mses,mses_nox\n",
    "\n",
    "\n",
    "def run_model(z, p2, x, y, seq=20):\n",
    "    torch.manual_seed(0)\n",
    "    model=gruvae.GRUVAE(1,1,5,5,5,5,2,5,10,3,0.3)\n",
    "    train_loader, val_loader, test_loader, scaler\\\n",
    "        = create_inout_sequences(z, p2, x, y, seq, 800, 100, 100, 10)\n",
    "    vae_trainer = train.AutoEncoderTrainer(model, optim.Adam,\\\n",
    "                            train_loader, val_loader,\\\n",
    "                            test_loader, scaler, lr=0.001, lam=0.01)\n",
    "    _,_,model = vae_trainer.train_and_evaluate(50)\n",
    "    return train_loader, val_loader, test_loader, model, scaler\n",
    "\n",
    "\n",
    "train_loader, val_loader, test_loader, model, scaler = run_model(z, p2, x, y)\n",
    "full_mses, full_mses_res = obtain_errors(model, 50, train_loader,\\\n",
    "                          val_loader, test_loader, scaler)  \n",
    "        \n",
    "print(t_test([i.tolist() for i in full_mses],\\\n",
    "             [i.tolist() for i in full_mses_res],alternative='greater'))\n",
    "             \n",
    "def calc_pvalues(sig_to_noise_low=\"default\", sig_to_noise_upp=\"default\"):\n",
    "    \n",
    "    if sig_to_noise_low !=\"default\":\n",
    "        data_low = generate(sig_to_noise_low)\n",
    "        z_low = data_low[\"z\"].tolist()\n",
    "        p_low = data_low[\"p2\"].tolist()\n",
    "        x_low = data_low[\"x\"].tolist()\n",
    "        y_low = data_low[\"y\"].tolist()\n",
    "        \n",
    "        train_loader, val_loader, test_loader, model, scaler\\\n",
    "            = run_model(z_low, p_low, x_low, y_low)\n",
    "        full_mses, full_mses_res = obtain_errors(model, 50, train_loader,\\\n",
    "            val_loader, test_loader, scaler)  \n",
    "        p_value_low = t_test([i.tolist() for i in full_mses],\\\n",
    "            [i.tolist() for i in full_mses_res],alternative='less')\n",
    "    \n",
    "    if sig_to_noise_upp !=\"default\":\n",
    "        data_upp = generate(sig_to_noise_upp)\n",
    "        z_upp = data_upp[\"z\"].tolist()\n",
    "        p_upp = data_upp[\"p2\"].tolist()\n",
    "        x_upp = data_upp[\"x\"].tolist()\n",
    "        y_upp = data_upp[\"y\"].tolist()\n",
    "   \n",
    "        train_loader, val_loader, test_loader, model, scaler\\\n",
    "            = run_model(z_upp, p_upp, x_upp, y_upp)\n",
    "        full_mses, full_mses_res = obtain_errors(model, 50, train_loader,\\\n",
    "            val_loader, test_loader, scaler)  \n",
    "        p_value_upp = t_test([i.tolist() for i in full_mses],\\\n",
    "            [i.tolist() for i in full_mses_res],alternative='less')\n",
    "    \n",
    "    if  sig_to_noise_low!=\"default\" and sig_to_noise_upp!=\"default\":   \n",
    "        return p_value_low, p_value_upp\n",
    "    elif sig_to_noise_low!=\"default\" and sig_to_noise_upp==\"default\":\n",
    "        return p_value_low\n",
    "    elif sig_to_noise_upp!=\"default\" and sig_to_noise_low==\"default\":\n",
    "        return p_value_upp\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    \n",
    "def vary_alpha(trials, sig_to_noise_low, sig_to_noise_upp, type=\"bisection\",\\\n",
    "               step=0.1):\n",
    "    p_value_low, p_value_upp = calc_pvalues(sig_to_noise_low,sig_to_noise_upp)    \n",
    "    print(p_value_low, p_value_upp)\n",
    "    \n",
    "    if p_value_low<0.05 and p_value_upp<0.05:\n",
    "        print(\"enter new bounds\")\n",
    "        return None\n",
    "    elif p_value_low>0.05 and p_value_upp>0.05:\n",
    "        print(\"enter new bounds\")\n",
    "        return None\n",
    "    c=0\n",
    "    if type==\"bisection\":\n",
    "        prev_low = 0\n",
    "        prev_p = 0\n",
    "        for i in range(trials):\n",
    "            print(f\"\\tsig_to_noise_low: {sig_to_noise_low}, p_low: {p_value_low}, sig_to_noise_upp: {sig_to_noise_upp}, p_upp: {p_value_upp}\")            \n",
    "            prev_low = sig_to_noise_low\n",
    "            prev_p = p_value_low\n",
    "            if p_value_low>0.05:\n",
    "                sig_to_noise_low = (sig_to_noise_upp+sig_to_noise_low)/2\n",
    "                p_value_low = calc_pvalues(sig_to_noise_low=sig_to_noise_low)\n",
    "            if p_value_low<0.05:\n",
    "                sig_to_noise_upp = sig_to_noise_low\n",
    "                sig_to_noise_low = prev_low\n",
    "                p_value_upp = p_value_low\n",
    "                p_value_low = prev_p\n",
    "    else:\n",
    "        while c==0:\n",
    "            sig_to_noise_low+=step\n",
    "            p_value_low = calc_pvalues(sig_to_noise_low=sig_to_noise_low)\n",
    "            print(f\"\\tsig_to_noise_low: {sig_to_noise_low}, p_low: {p_value_low}, sig_to_noise_upp: {sig_to_noise_upp}, p_upp: {p_value_upp}\")\n",
    "            if p_value_low<0.05:       \n",
    "                break\n",
    "\n",
    "\n",
    "def vary_seq(seqs, z, p2, x, y):\n",
    "    for i in seqs:\n",
    "        train_loader, val_loader, test_loader, model, scaler\\\n",
    "            = run_model(z, p2, x, y, i)\n",
    "        full_mses, full_mses_res = obtain_errors(model, 50, train_loader,\\\n",
    "                          val_loader, test_loader, scaler) \n",
    "        p_val = t_test([i.tolist() for i in full_mses],\\\n",
    "             [i.tolist() for i in full_mses_res],alternative='less')  \n",
    "        print(f\"\\tlength: {i}, p_val: {p_val}\")\n",
    "\n",
    "'''\n",
    "if __name__==\"__main__\":\n",
    "    #vary_alpha(1,5, type=\"e\", step=1)\n",
    "    #vary_alpha(3,4, type=\"e\", step=0.1)\n",
    "    #vary_alpha(3,3.1, type=\"e\", step=0.01) #3.05\n",
    "    \n",
    "    #vary_alpha(8,0.5,10)\n",
    "    vary_seq([4,6,8,10,12,14,16], z, p2, x, y)\n",
    "'''   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db35aff",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f341ffe6",
   "metadata": {},
   "source": [
    "# case b: test relationship between X_j and X_k "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968932ca",
   "metadata": {},
   "source": [
    "### generate data (synthetic datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89cbebb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>p</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.608329</td>\n",
       "      <td>1.354164</td>\n",
       "      <td>1.608329</td>\n",
       "      <td>1.315905</td>\n",
       "      <td>1.608329</td>\n",
       "      <td>1.107953</td>\n",
       "      <td>1.315905</td>\n",
       "      <td>1.608329</td>\n",
       "      <td>1.608329</td>\n",
       "      <td>1.608329</td>\n",
       "      <td>0.611221</td>\n",
       "      <td>0.768904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.668109</td>\n",
       "      <td>1.668109</td>\n",
       "      <td>1.608329</td>\n",
       "      <td>1.315905</td>\n",
       "      <td>1.668109</td>\n",
       "      <td>1.315905</td>\n",
       "      <td>1.315905</td>\n",
       "      <td>1.678455</td>\n",
       "      <td>1.608329</td>\n",
       "      <td>1.315905</td>\n",
       "      <td>0.429496</td>\n",
       "      <td>0.650701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.527050</td>\n",
       "      <td>1.416383</td>\n",
       "      <td>1.671514</td>\n",
       "      <td>1.527050</td>\n",
       "      <td>1.671514</td>\n",
       "      <td>1.731134</td>\n",
       "      <td>1.315905</td>\n",
       "      <td>1.315905</td>\n",
       "      <td>1.315905</td>\n",
       "      <td>1.608329</td>\n",
       "      <td>0.272099</td>\n",
       "      <td>0.587211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.373281</td>\n",
       "      <td>1.415553</td>\n",
       "      <td>1.301101</td>\n",
       "      <td>1.272908</td>\n",
       "      <td>1.288102</td>\n",
       "      <td>1.555777</td>\n",
       "      <td>1.315905</td>\n",
       "      <td>1.407814</td>\n",
       "      <td>1.415144</td>\n",
       "      <td>1.608329</td>\n",
       "      <td>0.348170</td>\n",
       "      <td>0.536704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.288102</td>\n",
       "      <td>1.626617</td>\n",
       "      <td>1.364817</td>\n",
       "      <td>1.277590</td>\n",
       "      <td>1.302746</td>\n",
       "      <td>1.678455</td>\n",
       "      <td>1.556358</td>\n",
       "      <td>1.619606</td>\n",
       "      <td>1.306780</td>\n",
       "      <td>1.382071</td>\n",
       "      <td>0.217977</td>\n",
       "      <td>0.478136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1.343001</td>\n",
       "      <td>1.106226</td>\n",
       "      <td>1.143164</td>\n",
       "      <td>1.144724</td>\n",
       "      <td>1.352054</td>\n",
       "      <td>1.112471</td>\n",
       "      <td>1.104033</td>\n",
       "      <td>1.142985</td>\n",
       "      <td>1.348970</td>\n",
       "      <td>1.349344</td>\n",
       "      <td>0.011240</td>\n",
       "      <td>-0.100488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1.397761</td>\n",
       "      <td>1.344559</td>\n",
       "      <td>1.356790</td>\n",
       "      <td>1.347795</td>\n",
       "      <td>1.357322</td>\n",
       "      <td>1.144504</td>\n",
       "      <td>1.144095</td>\n",
       "      <td>1.143972</td>\n",
       "      <td>1.351344</td>\n",
       "      <td>1.390605</td>\n",
       "      <td>-0.066545</td>\n",
       "      <td>-0.101959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1.348506</td>\n",
       "      <td>1.141417</td>\n",
       "      <td>1.105830</td>\n",
       "      <td>1.111658</td>\n",
       "      <td>1.344999</td>\n",
       "      <td>1.352818</td>\n",
       "      <td>1.146729</td>\n",
       "      <td>1.396199</td>\n",
       "      <td>1.396842</td>\n",
       "      <td>1.352107</td>\n",
       "      <td>-0.056218</td>\n",
       "      <td>-0.108295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1.152360</td>\n",
       "      <td>1.147246</td>\n",
       "      <td>1.103625</td>\n",
       "      <td>1.141324</td>\n",
       "      <td>1.142688</td>\n",
       "      <td>1.353982</td>\n",
       "      <td>1.145131</td>\n",
       "      <td>1.358487</td>\n",
       "      <td>1.355289</td>\n",
       "      <td>1.101786</td>\n",
       "      <td>0.107108</td>\n",
       "      <td>-0.116596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1.395104</td>\n",
       "      <td>1.356745</td>\n",
       "      <td>1.390535</td>\n",
       "      <td>1.348043</td>\n",
       "      <td>1.142210</td>\n",
       "      <td>1.138361</td>\n",
       "      <td>1.356235</td>\n",
       "      <td>1.108647</td>\n",
       "      <td>1.110168</td>\n",
       "      <td>1.352023</td>\n",
       "      <td>0.012406</td>\n",
       "      <td>-0.125639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           x1        x2        x3        x4        x5        x6        x7  \\\n",
       "0    1.608329  1.354164  1.608329  1.315905  1.608329  1.107953  1.315905   \n",
       "1    1.668109  1.668109  1.608329  1.315905  1.668109  1.315905  1.315905   \n",
       "2    1.527050  1.416383  1.671514  1.527050  1.671514  1.731134  1.315905   \n",
       "3    1.373281  1.415553  1.301101  1.272908  1.288102  1.555777  1.315905   \n",
       "4    1.288102  1.626617  1.364817  1.277590  1.302746  1.678455  1.556358   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "995  1.343001  1.106226  1.143164  1.144724  1.352054  1.112471  1.104033   \n",
       "996  1.397761  1.344559  1.356790  1.347795  1.357322  1.144504  1.144095   \n",
       "997  1.348506  1.141417  1.105830  1.111658  1.344999  1.352818  1.146729   \n",
       "998  1.152360  1.147246  1.103625  1.141324  1.142688  1.353982  1.145131   \n",
       "999  1.395104  1.356745  1.390535  1.348043  1.142210  1.138361  1.356235   \n",
       "\n",
       "           x8        x9       x10         p         z  \n",
       "0    1.608329  1.608329  1.608329  0.611221  0.768904  \n",
       "1    1.678455  1.608329  1.315905  0.429496  0.650701  \n",
       "2    1.315905  1.315905  1.608329  0.272099  0.587211  \n",
       "3    1.407814  1.415144  1.608329  0.348170  0.536704  \n",
       "4    1.619606  1.306780  1.382071  0.217977  0.478136  \n",
       "..        ...       ...       ...       ...       ...  \n",
       "995  1.142985  1.348970  1.349344  0.011240 -0.100488  \n",
       "996  1.143972  1.351344  1.390605 -0.066545 -0.101959  \n",
       "997  1.396199  1.396842  1.352107 -0.056218 -0.108295  \n",
       "998  1.358487  1.355289  1.101786  0.107108 -0.116596  \n",
       "999  1.108647  1.110168  1.352023  0.012406 -0.125639  \n",
       "\n",
       "[1000 rows x 12 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "\n",
    "total_length=1000\n",
    "\n",
    "def sigmoid(x):\n",
    "        return 1 / (1 + math.exp(-x))\n",
    "    \n",
    "def generate(sig_to_noise): \n",
    "    np.random.seed(0)\n",
    "    z = [1,1,1,1]\n",
    "    x_arr = np.full((10,4),1.0)\n",
    "    x_arr_unini = np.full((10,total_length),0.0)\n",
    "    x = np.hstack((x_arr, x_arr_unini))\n",
    "    \n",
    "    p = []\n",
    "    n = [3,3,3,3]\n",
    "    t1 = [3,3,3,3]\n",
    "    \n",
    "    \n",
    "    for i in range(4,total_length+4):   #time\n",
    "        z.append(math.tanh(z[i-1]+np.random.normal(0,0.01)))\n",
    "        p.append(z[i]**2+np.random.normal(0,0.05))\n",
    "        \n",
    "        for j in range(0,10):\n",
    "            k = random.randint(0,9)\n",
    "            m = random.randint(1,5)  #random lag\n",
    "            n = random.randint(1,5)  #random lag\n",
    "            term1 = sigmoid(z[i-m])\n",
    "            term2 = sigmoid(x[k][i-n])\n",
    "            noise = np.random.normal(0,1)\n",
    "            alpha = (abs(term1+term2)/sig_to_noise)/abs(noise)  \n",
    "                \n",
    "            x[j][i] = term1+term2+alpha*noise\n",
    "\n",
    "\n",
    "\n",
    "    x=x[:,-total_length:]    \n",
    "    p=p[-total_length:]\n",
    "    z=z[-total_length:]\n",
    "    \n",
    "     #table format 1\n",
    "    df2=pd.DataFrame({\"x1\":x[0,:]})\n",
    "    for m in range(1,10):\n",
    "        df2.insert(loc=len(df2.columns), column='x'+str(m+1), value=x[m,:])\n",
    "    \n",
    "    \n",
    "    df2.insert(loc=len(df2.columns), column='p', value=p)\n",
    "    df2.insert(loc=len(df2.columns), column='z', value=z)\n",
    "   \n",
    "    return df2\n",
    "\n",
    "\n",
    "df2=generate(10)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116e10ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(0,10):\n",
    "            #k = random.randint(0,10)\n",
    "            m = random.randint(1,5)  #random lag\n",
    "            n = random.randint(1,5)  #random lag\n",
    "            x[j][i] = sigmoid(z[i-m])+np.random.normal(0,0.01)\n",
    "            term1 = sigmoid(z[i-m])\n",
    "            term2 = sigmoid(x[j][i-n])\n",
    "            #term2 = sigmoid(x[k][i-n])\n",
    "            noise = np.random.normal(0,1)\n",
    "            alpha = (abs(term1+term2)/sig_to_noise)/abs(noise)\n",
    "            \n",
    "            y[j][i] = term1+term2+alpha*noise\n",
    "            #x[j][i] = term1+term2+alpha*noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2a52684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>p</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.608329</td>\n",
       "      <td>1.608329</td>\n",
       "      <td>1.354164</td>\n",
       "      <td>1.315905</td>\n",
       "      <td>1.608329</td>\n",
       "      <td>1.315905</td>\n",
       "      <td>1.272908</td>\n",
       "      <td>1.608329</td>\n",
       "      <td>1.354164</td>\n",
       "      <td>1.608329</td>\n",
       "      <td>0.611221</td>\n",
       "      <td>0.768904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.608329</td>\n",
       "      <td>1.720662</td>\n",
       "      <td>1.608329</td>\n",
       "      <td>1.272908</td>\n",
       "      <td>1.720662</td>\n",
       "      <td>1.315905</td>\n",
       "      <td>1.361069</td>\n",
       "      <td>1.608329</td>\n",
       "      <td>1.608329</td>\n",
       "      <td>1.315905</td>\n",
       "      <td>0.429496</td>\n",
       "      <td>0.650701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.555777</td>\n",
       "      <td>1.315905</td>\n",
       "      <td>1.639383</td>\n",
       "      <td>1.618962</td>\n",
       "      <td>1.608329</td>\n",
       "      <td>1.608329</td>\n",
       "      <td>1.361069</td>\n",
       "      <td>1.249404</td>\n",
       "      <td>1.341313</td>\n",
       "      <td>1.720662</td>\n",
       "      <td>0.272099</td>\n",
       "      <td>0.587211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.272908</td>\n",
       "      <td>1.341845</td>\n",
       "      <td>1.236405</td>\n",
       "      <td>1.249404</td>\n",
       "      <td>1.421345</td>\n",
       "      <td>1.639383</td>\n",
       "      <td>1.331295</td>\n",
       "      <td>1.236405</td>\n",
       "      <td>1.315905</td>\n",
       "      <td>1.574347</td>\n",
       "      <td>0.348170</td>\n",
       "      <td>0.536704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.407814</td>\n",
       "      <td>1.671514</td>\n",
       "      <td>1.341313</td>\n",
       "      <td>1.225893</td>\n",
       "      <td>1.292935</td>\n",
       "      <td>1.623495</td>\n",
       "      <td>1.679691</td>\n",
       "      <td>1.546581</td>\n",
       "      <td>1.324605</td>\n",
       "      <td>1.341845</td>\n",
       "      <td>0.217977</td>\n",
       "      <td>0.478136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1.360302</td>\n",
       "      <td>1.143031</td>\n",
       "      <td>1.109546</td>\n",
       "      <td>1.104964</td>\n",
       "      <td>1.396911</td>\n",
       "      <td>1.103047</td>\n",
       "      <td>1.104911</td>\n",
       "      <td>1.103526</td>\n",
       "      <td>1.359283</td>\n",
       "      <td>1.396118</td>\n",
       "      <td>0.011240</td>\n",
       "      <td>-0.100488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1.353517</td>\n",
       "      <td>1.404040</td>\n",
       "      <td>1.344584</td>\n",
       "      <td>1.348146</td>\n",
       "      <td>1.351520</td>\n",
       "      <td>1.135772</td>\n",
       "      <td>1.146517</td>\n",
       "      <td>1.105314</td>\n",
       "      <td>1.349916</td>\n",
       "      <td>1.404868</td>\n",
       "      <td>-0.066545</td>\n",
       "      <td>-0.101959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1.392622</td>\n",
       "      <td>1.151568</td>\n",
       "      <td>1.101031</td>\n",
       "      <td>1.145472</td>\n",
       "      <td>1.351520</td>\n",
       "      <td>1.394397</td>\n",
       "      <td>1.142917</td>\n",
       "      <td>1.395839</td>\n",
       "      <td>1.400229</td>\n",
       "      <td>1.406061</td>\n",
       "      <td>-0.056218</td>\n",
       "      <td>-0.108295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1.108318</td>\n",
       "      <td>1.109491</td>\n",
       "      <td>1.140998</td>\n",
       "      <td>1.147528</td>\n",
       "      <td>1.152462</td>\n",
       "      <td>1.354578</td>\n",
       "      <td>1.110396</td>\n",
       "      <td>1.404064</td>\n",
       "      <td>1.400229</td>\n",
       "      <td>1.151832</td>\n",
       "      <td>0.107108</td>\n",
       "      <td>-0.116596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1.403097</td>\n",
       "      <td>1.403383</td>\n",
       "      <td>1.390539</td>\n",
       "      <td>1.354799</td>\n",
       "      <td>1.145878</td>\n",
       "      <td>1.112150</td>\n",
       "      <td>1.354284</td>\n",
       "      <td>1.147028</td>\n",
       "      <td>1.152936</td>\n",
       "      <td>1.402920</td>\n",
       "      <td>0.012406</td>\n",
       "      <td>-0.125639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           x1        x2        x3        x4        x5        x6        x7  \\\n",
       "0    1.608329  1.608329  1.354164  1.315905  1.608329  1.315905  1.272908   \n",
       "1    1.608329  1.720662  1.608329  1.272908  1.720662  1.315905  1.361069   \n",
       "2    1.555777  1.315905  1.639383  1.618962  1.608329  1.608329  1.361069   \n",
       "3    1.272908  1.341845  1.236405  1.249404  1.421345  1.639383  1.331295   \n",
       "4    1.407814  1.671514  1.341313  1.225893  1.292935  1.623495  1.679691   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "995  1.360302  1.143031  1.109546  1.104964  1.396911  1.103047  1.104911   \n",
       "996  1.353517  1.404040  1.344584  1.348146  1.351520  1.135772  1.146517   \n",
       "997  1.392622  1.151568  1.101031  1.145472  1.351520  1.394397  1.142917   \n",
       "998  1.108318  1.109491  1.140998  1.147528  1.152462  1.354578  1.110396   \n",
       "999  1.403097  1.403383  1.390539  1.354799  1.145878  1.112150  1.354284   \n",
       "\n",
       "           x8        x9       x10         p         z  \n",
       "0    1.608329  1.354164  1.608329  0.611221  0.768904  \n",
       "1    1.608329  1.608329  1.315905  0.429496  0.650701  \n",
       "2    1.249404  1.341313  1.720662  0.272099  0.587211  \n",
       "3    1.236405  1.315905  1.574347  0.348170  0.536704  \n",
       "4    1.546581  1.324605  1.341845  0.217977  0.478136  \n",
       "..        ...       ...       ...       ...       ...  \n",
       "995  1.103526  1.359283  1.396118  0.011240 -0.100488  \n",
       "996  1.105314  1.349916  1.404868 -0.066545 -0.101959  \n",
       "997  1.395839  1.400229  1.406061 -0.056218 -0.108295  \n",
       "998  1.404064  1.400229  1.151832  0.107108 -0.116596  \n",
       "999  1.147028  1.152936  1.402920  0.012406 -0.125639  \n",
       "\n",
       "[1000 rows x 12 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "\n",
    "total_length=1000\n",
    "\n",
    "def sigmoid(x):\n",
    "        return 1 / (1 + math.exp(-x))\n",
    "    \n",
    "def generate(sig_to_noise): \n",
    "    np.random.seed(0)\n",
    "    z = [1,1,1,1]\n",
    "    x_arr = np.full((10,4),1.0)\n",
    "    x_arr_unini = np.full((10,total_length),0.0)\n",
    "    x = np.hstack((x_arr, x_arr_unini))\n",
    "    \n",
    "    p = []\n",
    "    n = [3,3,3,3]\n",
    "    t1 = [3,3,3,3]\n",
    "    for i in range(4,total_length+4):   #time\n",
    "        z.append(math.tanh(z[i-1]+np.random.normal(0,0.01)))\n",
    "        p.append(z[i]**2+np.random.normal(0,0.05))\n",
    "        \n",
    "        for j in range(0,10):\n",
    "            m = random.randint(1,5)  #random lag\n",
    "            n = random.randint(1,5)  #random lag\n",
    "            term1 = sigmoid(z[i-m])\n",
    "            term2 = sigmoid(x[j][i-n])\n",
    "            noise = np.random.normal(0,1)\n",
    "            alpha = (abs(term1+term2)/sig_to_noise)/abs(noise)  \n",
    "                \n",
    "            x[j][i] = term1+term2+alpha*noise\n",
    "\n",
    "\n",
    "\n",
    "    x=x[:,-total_length:]    \n",
    "    p=p[-total_length:]\n",
    "    z=z[-total_length:]\n",
    "    \n",
    "     #table format 1\n",
    "    df2=pd.DataFrame({\"x1\":x[0,:]})\n",
    "    for m in range(1,10):\n",
    "        df2.insert(loc=len(df2.columns), column='x'+str(m+1), value=x[m,:])\n",
    "    \n",
    "    \n",
    "    df2.insert(loc=len(df2.columns), column='p', value=p)\n",
    "    df2.insert(loc=len(df2.columns), column='z', value=z)\n",
    "   \n",
    "    return df2\n",
    "\n",
    "\n",
    "df2=generate(10)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6d89aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(\"case_b.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7a7ab0",
   "metadata": {},
   "source": [
    "# main 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8ef755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from torch import optim\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "\n",
    "#os.chdir(\"/Users/yaohanxue/Desktop/hx_model\")\n",
    "import gruvae\n",
    "import train\n",
    "from data_loader import create_inout_sequences\n",
    "from functions import t_test\n",
    "from generate_data_b import generate\n",
    "\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"case_b.csv\")[:1000]\n",
    "\n",
    "\n",
    "m = random.randint(0, 9)\n",
    "x_j = data['x'+str(m+1)].tolist()\n",
    "\n",
    "numbers = list(range(0, 10))\n",
    "numbers.remove(m)\n",
    "l = random.choice(numbers)\n",
    "x_k = data['x'+str(l+1)].tolist()\n",
    "\n",
    "z = data[\"z\"].tolist()\n",
    "p = data[\"p\"].tolist()\n",
    "\n",
    "\n",
    "  \n",
    "def obtain_errors(model,trials, train_loader,\\\n",
    "                  val_loader, test_loader, scaler, lam=0,\\\n",
    "                  model_type=\"full\", res=\"No\"):\n",
    "    torch.manual_seed(0)\n",
    "    mses = []\n",
    "    mses_nox = []\n",
    "    vae_trainer = train.AutoEncoderTrainer(model, optim.Adam,\\\n",
    "                    train_loader, val_loader,\\\n",
    "                    test_loader, scaler, 0.001, lam, model_type)\n",
    "    for i in range(trials):\n",
    "        _,mse,mse_nox,_ = vae_trainer.train_val_test_iter(test_loader,\\\n",
    "                                                          \"test\", res)\n",
    "        mses.append(mse)\n",
    "        mses_nox.append(mse_nox)\n",
    "    return mses,mses_nox\n",
    "\n",
    "\n",
    "def run_model(z, p, x_j, x_k, seq=20):\n",
    "    torch.manual_seed(0)\n",
    "    model=gruvae.GRUVAE(1,1,5,5,5,5,2,5,10,3,0.3)\n",
    "    train_loader, val_loader, test_loader, scaler\\\n",
    "        = create_inout_sequences(z, p, x_j, x_k, seq, 800, 100, 100, 10)\n",
    "    vae_trainer = train.AutoEncoderTrainer(model, optim.Adam,\\\n",
    "                            train_loader, val_loader,\\\n",
    "                            test_loader, scaler, lr=0.001, lam=0.01)\n",
    "    _,_,model = vae_trainer.train_and_evaluate(50)\n",
    "    return train_loader, val_loader, test_loader, model, scaler\n",
    "\n",
    "\n",
    "train_loader, val_loader, test_loader, model, scaler = run_model(z, p, x_j, x_k)\n",
    "full_mses, full_mses_res = obtain_errors(model, 50, train_loader,\\\n",
    "                          val_loader, test_loader, scaler)  \n",
    "        \n",
    "print(t_test([i.tolist() for i in full_mses],\\\n",
    "             [i.tolist() for i in full_mses_res],alternative='greater'))\n",
    "             \n",
    "def calc_pvalues(sig_to_noise_low=\"default\", sig_to_noise_upp=\"default\"):\n",
    "    \n",
    "    if sig_to_noise_low !=\"default\":\n",
    "        data_low = generate(sig_to_noise_low)\n",
    "        z_low = data_low[\"z\"].tolist()\n",
    "        p_low = data_low[\"p\"].tolist()\n",
    "        x_low = data_low['x'+str(m+1)].tolist()\n",
    "        y_low = data_low['x'+str(l+1)].tolist()\n",
    "        \n",
    "        train_loader, val_loader, test_loader, model, scaler\\\n",
    "            = run_model(z_low, p_low, x_low, y_low)\n",
    "        full_mses, full_mses_res = obtain_errors(model, 50, train_loader,\\\n",
    "            val_loader, test_loader, scaler)  \n",
    "        p_value_low = t_test([i.tolist() for i in full_mses],\\\n",
    "            [i.tolist() for i in full_mses_res],alternative='less')\n",
    "    \n",
    "    if sig_to_noise_upp !=\"default\":\n",
    "        data_upp = generate(sig_to_noise_upp)\n",
    "        z_upp = data_upp[\"z\"].tolist()\n",
    "        p_upp = data_upp[\"p\"].tolist()\n",
    "        x_upp = data_upp['x'+str(m+1)].tolist()\n",
    "        y_upp = data_upp['x'+str(l+1)].tolist()\n",
    "   \n",
    "        train_loader, val_loader, test_loader, model, scaler\\\n",
    "            = run_model(z_upp, p_upp, x_upp, y_upp)\n",
    "        full_mses, full_mses_res = obtain_errors(model, 50, train_loader,\\\n",
    "            val_loader, test_loader, scaler)  \n",
    "        p_value_upp = t_test([i.tolist() for i in full_mses],\\\n",
    "            [i.tolist() for i in full_mses_res],alternative='less')\n",
    "    \n",
    "    if  sig_to_noise_low!=\"default\" and sig_to_noise_upp!=\"default\":   \n",
    "        return p_value_low, p_value_upp\n",
    "    elif sig_to_noise_low!=\"default\" and sig_to_noise_upp==\"default\":\n",
    "        return p_value_low\n",
    "    elif sig_to_noise_upp!=\"default\" and sig_to_noise_low==\"default\":\n",
    "        return p_value_upp\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    \n",
    "def vary_alpha(trials, sig_to_noise_low, sig_to_noise_upp, type=\"bisection\",\\\n",
    "               step=0.1):\n",
    "    p_value_low, p_value_upp = calc_pvalues(sig_to_noise_low,sig_to_noise_upp)    \n",
    "    print(p_value_low, p_value_upp)\n",
    "    \n",
    "    if p_value_low<0.05 and p_value_upp<0.05:\n",
    "        print(\"enter new bounds\")\n",
    "        return None\n",
    "    elif p_value_low>0.05 and p_value_upp>0.05:\n",
    "        print(\"enter new bounds\")\n",
    "        return None\n",
    "    c=0\n",
    "    if type==\"bisection\":\n",
    "        prev_low = 0\n",
    "        prev_p = 0\n",
    "        for i in range(trials):\n",
    "            print(f\"\\tsig_to_noise_low: {sig_to_noise_low}, p_low: {p_value_low}, sig_to_noise_upp: {sig_to_noise_upp}, p_upp: {p_value_upp}\")            \n",
    "            prev_low = sig_to_noise_low\n",
    "            prev_p = p_value_low\n",
    "            if p_value_low>0.05:\n",
    "                sig_to_noise_low = (sig_to_noise_upp+sig_to_noise_low)/2\n",
    "                p_value_low = calc_pvalues(sig_to_noise_low=sig_to_noise_low)\n",
    "            if p_value_low<0.05:\n",
    "                sig_to_noise_upp = sig_to_noise_low\n",
    "                sig_to_noise_low = prev_low\n",
    "                p_value_upp = p_value_low\n",
    "                p_value_low = prev_p\n",
    "    else:\n",
    "        while c==0:\n",
    "            sig_to_noise_low+=step\n",
    "            p_value_low = calc_pvalues(sig_to_noise_low=sig_to_noise_low)\n",
    "            print(f\"\\tsig_to_noise_low: {sig_to_noise_low}, p_low: {p_value_low}, sig_to_noise_upp: {sig_to_noise_upp}, p_upp: {p_value_upp}\")\n",
    "            if p_value_low<0.05:       \n",
    "                break\n",
    "\n",
    "\n",
    "def vary_seq(seqs, z, p, x_j, x_k):\n",
    "    for i in seqs:\n",
    "        train_loader, val_loader, test_loader, model, scaler\\\n",
    "            = run_model(z, p, x_j, x_k, i)\n",
    "        full_mses, full_mses_res = obtain_errors(model, 50, train_loader,\\\n",
    "                          val_loader, test_loader, scaler) \n",
    "        p_val = t_test([i.tolist() for i in full_mses],\\\n",
    "             [i.tolist() for i in full_mses_res],alternative='less')  \n",
    "        print(f\"\\tlength: {i}, p_val: {p_val}\")\n",
    "\n",
    "'''\n",
    "if __name__==\"__main__\":\n",
    "    #vary_alpha(1,5, type=\"e\", step=1)\n",
    "    #vary_alpha(3,4, type=\"e\", step=0.1)\n",
    "    #vary_alpha(3,3.1, type=\"e\", step=0.01) #3.05\n",
    "    \n",
    "    #vary_alpha(8,0.5,10)\n",
    "    vary_seq([4,6,8,10,12,14,16], z, p, x_j, x_k)\n",
    "'''   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4673a179",
   "metadata": {},
   "source": [
    "# main 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02795008",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from torch import optim\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "\n",
    "#os.chdir(\"/Users/yaohanxue/Desktop/hx_model\")\n",
    "import gruvae\n",
    "import train\n",
    "from data_loader import create_inout_sequences\n",
    "from functions import t_test\n",
    "from generate_data_b import generate\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"case_b.csv\")[:1000]\n",
    "\n",
    "\n",
    "z = data[\"z\"].tolist()\n",
    "\n",
    "m = random.randint(0, 9)\n",
    "x_j = data['x'+str(m+1)].tolist()\n",
    "\n",
    "numbers = list(range(0, 10))\n",
    "numbers.remove(m)\n",
    "l = random.choice(numbers)\n",
    "x_k = data['x'+str(l+1)].tolist()\n",
    "\n",
    "data = data.iloc[: , 1:]\n",
    "p1 = data[data.columns.difference(['x'+str(m+1), 'y'+str(l+1), \"z\"])].values.tolist()\n",
    "\n",
    "\n",
    "  \n",
    "def obtain_errors(model,trials, train_loader,\\\n",
    "                  val_loader, test_loader, scaler, lam=0,\\\n",
    "                  model_type=\"full\", res=\"No\"):\n",
    "    torch.manual_seed(0)\n",
    "    mses = []\n",
    "    mses_nox = []\n",
    "    vae_trainer = train.AutoEncoderTrainer(model, optim.Adam,\\\n",
    "                    train_loader, val_loader,\\\n",
    "                    test_loader, scaler, 0.001, lam, model_type)\n",
    "    for i in range(trials):\n",
    "        _,mse,mse_nox,_ = vae_trainer.train_val_test_iter(test_loader,\\\n",
    "                                                          \"test\", res)\n",
    "        mses.append(mse)\n",
    "        mses_nox.append(mse_nox)\n",
    "    return mses,mses_nox\n",
    "\n",
    "\n",
    "def run_model(z, p1, x_j, x_k, seq=20):\n",
    "    torch.manual_seed(0)\n",
    "    model=gruvae.GRUVAE(1,1,5,5,5,5,2,5,10,3,0.3)\n",
    "    train_loader, val_loader, test_loader, scaler\\\n",
    "        = create_inout_sequences(z, p1, x_i, x_j, seq, 800, 100, 100, 10)\n",
    "    vae_trainer = train.AutoEncoderTrainer(model, optim.Adam,\\\n",
    "                            train_loader, val_loader,\\\n",
    "                            test_loader, scaler, lr=0.001, lam=0.01)\n",
    "    _,_,model = vae_trainer.train_and_evaluate(50)\n",
    "    return train_loader, val_loader, test_loader, model, scaler\n",
    "\n",
    "\n",
    "train_loader, val_loader, test_loader, model, scaler = run_model(z, p1, x_j, x_k)\n",
    "full_mses, full_mses_res = obtain_errors(model, 50, train_loader,\\\n",
    "                          val_loader, test_loader, scaler)  \n",
    "        \n",
    "print(t_test([i.tolist() for i in full_mses],\\\n",
    "             [i.tolist() for i in full_mses_res],alternative='greater'))\n",
    "             \n",
    "def calc_pvalues(sig_to_noise_low=\"default\", sig_to_noise_upp=\"default\"):\n",
    "    \n",
    "    if sig_to_noise_low !=\"default\":\n",
    "        data_low = generate(sig_to_noise_low)\n",
    "        z_low = data_low[\"z\"].tolist()\n",
    "        p_low = data_low[\"p1\"].tolist()\n",
    "        x_low = data_low['x'+str(m+1)].tolist()\n",
    "        y_low = data_low['x'+str(l+1)].tolist()\n",
    "        \n",
    "        train_loader, val_loader, test_loader, model, scaler\\\n",
    "            = run_model(z_low, p_low, x_low, y_low)\n",
    "        full_mses, full_mses_res = obtain_errors(model, 50, train_loader,\\\n",
    "            val_loader, test_loader, scaler)  \n",
    "        p_value_low = t_test([i.tolist() for i in full_mses],\\\n",
    "            [i.tolist() for i in full_mses_res],alternative='less')\n",
    "    \n",
    "    if sig_to_noise_upp !=\"default\":\n",
    "        data_upp = generate(sig_to_noise_upp)\n",
    "        z_upp = data_upp[\"z\"].tolist()\n",
    "        p_upp = data_upp[\"p1\"].tolist()\n",
    "        x_upp = data_upp['x'+str(m+1)].tolist()\n",
    "        y_upp = data_upp['x'+str(l+1)].tolist()\n",
    "   \n",
    "        train_loader, val_loader, test_loader, model, scaler\\\n",
    "            = run_model(z_upp, p_upp, x_upp, y_upp)\n",
    "        full_mses, full_mses_res = obtain_errors(model, 50, train_loader,\\\n",
    "            val_loader, test_loader, scaler)  \n",
    "        p_value_upp = t_test([i.tolist() for i in full_mses],\\\n",
    "            [i.tolist() for i in full_mses_res],alternative='less')\n",
    "    \n",
    "    if  sig_to_noise_low!=\"default\" and sig_to_noise_upp!=\"default\":   \n",
    "        return p_value_low, p_value_upp\n",
    "    elif sig_to_noise_low!=\"default\" and sig_to_noise_upp==\"default\":\n",
    "        return p_value_low\n",
    "    elif sig_to_noise_upp!=\"default\" and sig_to_noise_low==\"default\":\n",
    "        return p_value_upp\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    \n",
    "def vary_alpha(trials, sig_to_noise_low, sig_to_noise_upp, type=\"bisection\",\\\n",
    "               step=0.1):\n",
    "    p_value_low, p_value_upp = calc_pvalues(sig_to_noise_low,sig_to_noise_upp)    \n",
    "    print(p_value_low, p_value_upp)\n",
    "    \n",
    "    if p_value_low<0.05 and p_value_upp<0.05:\n",
    "        print(\"enter new bounds\")\n",
    "        return None\n",
    "    elif p_value_low>0.05 and p_value_upp>0.05:\n",
    "        print(\"enter new bounds\")\n",
    "        return None\n",
    "    c=0\n",
    "    if type==\"bisection\":\n",
    "        prev_low = 0\n",
    "        prev_p = 0\n",
    "        for i in range(trials):\n",
    "            print(f\"\\tsig_to_noise_low: {sig_to_noise_low}, p_low: {p_value_low}, sig_to_noise_upp: {sig_to_noise_upp}, p_upp: {p_value_upp}\")            \n",
    "            prev_low = sig_to_noise_low\n",
    "            prev_p = p_value_low\n",
    "            if p_value_low>0.05:\n",
    "                sig_to_noise_low = (sig_to_noise_upp+sig_to_noise_low)/2\n",
    "                p_value_low = calc_pvalues(sig_to_noise_low=sig_to_noise_low)\n",
    "            if p_value_low<0.05:\n",
    "                sig_to_noise_upp = sig_to_noise_low\n",
    "                sig_to_noise_low = prev_low\n",
    "                p_value_upp = p_value_low\n",
    "                p_value_low = prev_p\n",
    "    else:\n",
    "        while c==0:\n",
    "            sig_to_noise_low+=step\n",
    "            p_value_low = calc_pvalues(sig_to_noise_low=sig_to_noise_low)\n",
    "            print(f\"\\tsig_to_noise_low: {sig_to_noise_low}, p_low: {p_value_low}, sig_to_noise_upp: {sig_to_noise_upp}, p_upp: {p_value_upp}\")\n",
    "            if p_value_low<0.05:       \n",
    "                break\n",
    "\n",
    "\n",
    "def vary_seq(seqs, z, p1, x_j, x_k):\n",
    "    for i in seqs:\n",
    "        train_loader, val_loader, test_loader, model, scaler\\\n",
    "            = run_model(z, p1, x_j, x_k, i)\n",
    "        full_mses, full_mses_res = obtain_errors(model, 50, train_loader,\\\n",
    "                          val_loader, test_loader, scaler) \n",
    "        p_val = t_test([i.tolist() for i in full_mses],\\\n",
    "             [i.tolist() for i in full_mses_res],alternative='less')  \n",
    "        print(f\"\\tlength: {i}, p_val: {p_val}\")\n",
    "\n",
    "'''\n",
    "if __name__==\"__main__\":\n",
    "    #vary_alpha(1,5, type=\"e\", step=1)\n",
    "    #vary_alpha(3,4, type=\"e\", step=0.1)\n",
    "    #vary_alpha(3,3.1, type=\"e\", step=0.01) #3.05\n",
    "    \n",
    "    #vary_alpha(8,0.5,10)\n",
    "    vary_seq([4,6,8,10,12,14,16], z, p1, x_j, x_k)\n",
    "'''   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3feda1e",
   "metadata": {},
   "source": [
    "# main 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dad0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from torch import optim\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import pandas as pd  # to load the dataframe\n",
    "from sklearn.preprocessing import StandardScaler  # to standardize the features\n",
    "from sklearn.decomposition import PCA  # to apply PCA\n",
    "\n",
    "\n",
    "\n",
    "#os.chdir(\"/Users/yaohanxue/Desktop/hx_model\")\n",
    "import gruvae\n",
    "import train\n",
    "from data_loader import create_inout_sequences\n",
    "from functions import t_test\n",
    "from generate_data_b import generate\n",
    "\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"case_b.csv\")[:1000]\n",
    "\n",
    "\n",
    "m = random.randint(0, 9)\n",
    "x_j = data['x'+str(m+1)].tolist()\n",
    "\n",
    "numbers = list(range(0, 10))\n",
    "numbers.remove(m)\n",
    "l = random.choice(numbers)\n",
    "x_k = data['x'+str(l+1)].tolist()\n",
    "\n",
    "z = data[\"z\"].tolist()\n",
    "\n",
    "data = data.iloc[: , 1:]\n",
    "p1 = data[data.columns.difference(['x'+str(m+1), 'x'+str(l+1), \"z\"])]\n",
    "\n",
    "#PCA\n",
    "\n",
    "#convert the dataset into a pandas data frame\n",
    "df = pd.DataFrame(p1)\n",
    "\n",
    "#Standardize the features\n",
    "#Create an object of StandardScaler which is present in sklearn.preprocessing\n",
    "scalar = StandardScaler()\n",
    "scaled_data = pd.DataFrame(scalar.fit_transform(df), columns=df.columns) #scaling the data\n",
    " \n",
    "#Applying PCA\n",
    "#Taking no. of Principal Components as 1\n",
    "pca = PCA(n_components = 1)\n",
    "pca.fit(scaled_data)\n",
    "data_pca = pca.transform(scaled_data)\n",
    "data_pca = pd.DataFrame(data_pca,columns=['PC1'])\n",
    "p2 = data_pca['PC1'].tolist()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "def obtain_errors(model,trials, train_loader,\\\n",
    "                  val_loader, test_loader, scaler, lam=0,\\\n",
    "                  model_type=\"full\", res=\"No\"):\n",
    "    torch.manual_seed(0)\n",
    "    mses = []\n",
    "    mses_nox = []\n",
    "    vae_trainer = train.AutoEncoderTrainer(model, optim.Adam,\\\n",
    "                    train_loader, val_loader,\\\n",
    "                    test_loader, scaler, 0.001, lam, model_type)\n",
    "    for i in range(trials):\n",
    "        _,mse,mse_nox,_ = vae_trainer.train_val_test_iter(test_loader,\\\n",
    "                                                          \"test\", res)\n",
    "        mses.append(mse)\n",
    "        mses_nox.append(mse_nox)\n",
    "    return mses,mses_nox\n",
    "\n",
    "\n",
    "def run_model(z, p2, x_j, x_k, seq=20):\n",
    "    torch.manual_seed(0)\n",
    "    model=gruvae.GRUVAE(1,1,5,5,5,5,2,5,10,3,0.3)\n",
    "    train_loader, val_loader, test_loader, scaler\\\n",
    "        = create_inout_sequences(z, p2, x_j, x_k, seq, 800, 100, 100, 10)\n",
    "    vae_trainer = train.AutoEncoderTrainer(model, optim.Adam,\\\n",
    "                            train_loader, val_loader,\\\n",
    "                            test_loader, scaler, lr=0.001, lam=0.01)\n",
    "    _,_,model = vae_trainer.train_and_evaluate(50)\n",
    "    return train_loader, val_loader, test_loader, model, scaler\n",
    "\n",
    "\n",
    "train_loader, val_loader, test_loader, model, scaler = run_model(z, p2, x_j, x_k)\n",
    "full_mses, full_mses_res = obtain_errors(model, 50, train_loader,\\\n",
    "                          val_loader, test_loader, scaler)  \n",
    "        \n",
    "print(t_test([i.tolist() for i in full_mses],\\\n",
    "             [i.tolist() for i in full_mses_res],alternative='greater'))\n",
    "             \n",
    "def calc_pvalues(sig_to_noise_low=\"default\", sig_to_noise_upp=\"default\"):\n",
    "    \n",
    "    if sig_to_noise_low !=\"default\":\n",
    "        data_low = generate(sig_to_noise_low)\n",
    "        z_low = data_low[\"z\"].tolist()\n",
    "        p_low = data_low[\"p2\"].tolist()\n",
    "        x_low = data_low['x'+str(m+1)].tolist()\n",
    "        y_low = data_low['x'+str(l+1)].tolist()\n",
    "        \n",
    "        train_loader, val_loader, test_loader, model, scaler\\\n",
    "            = run_model(z_low, p_low, x_low, y_low)\n",
    "        full_mses, full_mses_res = obtain_errors(model, 50, train_loader,\\\n",
    "            val_loader, test_loader, scaler)  \n",
    "        p_value_low = t_test([i.tolist() for i in full_mses],\\\n",
    "            [i.tolist() for i in full_mses_res],alternative='less')\n",
    "    \n",
    "    if sig_to_noise_upp !=\"default\":\n",
    "        data_upp = generate(sig_to_noise_upp)\n",
    "        z_upp = data_upp[\"z\"].tolist()\n",
    "        p_upp = data_upp[\"p2\"].tolist()\n",
    "        x_upp = data_upp['x'+str(m+1)].tolist()\n",
    "        y_upp = data_upp['x'+str(l+1)].tolist()\n",
    "   \n",
    "        train_loader, val_loader, test_loader, model, scaler\\\n",
    "            = run_model(z_upp, p_upp, x_upp, y_upp)\n",
    "        full_mses, full_mses_res = obtain_errors(model, 50, train_loader,\\\n",
    "            val_loader, test_loader, scaler)  \n",
    "        p_value_upp = t_test([i.tolist() for i in full_mses],\\\n",
    "            [i.tolist() for i in full_mses_res],alternative='less')\n",
    "    \n",
    "    if  sig_to_noise_low!=\"default\" and sig_to_noise_upp!=\"default\":   \n",
    "        return p_value_low, p_value_upp\n",
    "    elif sig_to_noise_low!=\"default\" and sig_to_noise_upp==\"default\":\n",
    "        return p_value_low\n",
    "    elif sig_to_noise_upp!=\"default\" and sig_to_noise_low==\"default\":\n",
    "        return p_value_upp\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    \n",
    "def vary_alpha(trials, sig_to_noise_low, sig_to_noise_upp, type=\"bisection\",\\\n",
    "               step=0.1):\n",
    "    p_value_low, p_value_upp = calc_pvalues(sig_to_noise_low,sig_to_noise_upp)    \n",
    "    print(p_value_low, p_value_upp)\n",
    "    \n",
    "    if p_value_low<0.05 and p_value_upp<0.05:\n",
    "        print(\"enter new bounds\")\n",
    "        return None\n",
    "    elif p_value_low>0.05 and p_value_upp>0.05:\n",
    "        print(\"enter new bounds\")\n",
    "        return None\n",
    "    c=0\n",
    "    if type==\"bisection\":\n",
    "        prev_low = 0\n",
    "        prev_p = 0\n",
    "        for i in range(trials):\n",
    "            print(f\"\\tsig_to_noise_low: {sig_to_noise_low}, p_low: {p_value_low}, sig_to_noise_upp: {sig_to_noise_upp}, p_upp: {p_value_upp}\")            \n",
    "            prev_low = sig_to_noise_low\n",
    "            prev_p = p_value_low\n",
    "            if p_value_low>0.05:\n",
    "                sig_to_noise_low = (sig_to_noise_upp+sig_to_noise_low)/2\n",
    "                p_value_low = calc_pvalues(sig_to_noise_low=sig_to_noise_low)\n",
    "            if p_value_low<0.05:\n",
    "                sig_to_noise_upp = sig_to_noise_low\n",
    "                sig_to_noise_low = prev_low\n",
    "                p_value_upp = p_value_low\n",
    "                p_value_low = prev_p\n",
    "    else:\n",
    "        while c==0:\n",
    "            sig_to_noise_low+=step\n",
    "            p_value_low = calc_pvalues(sig_to_noise_low=sig_to_noise_low)\n",
    "            print(f\"\\tsig_to_noise_low: {sig_to_noise_low}, p_low: {p_value_low}, sig_to_noise_upp: {sig_to_noise_upp}, p_upp: {p_value_upp}\")\n",
    "            if p_value_low<0.05:       \n",
    "                break\n",
    "\n",
    "\n",
    "def vary_seq(seqs, z, p2, x_j, x_k):\n",
    "    for i in seqs:\n",
    "        train_loader, val_loader, test_loader, model, scaler\\\n",
    "            = run_model(z, p2, x_j, x_k, i)\n",
    "        full_mses, full_mses_res = obtain_errors(model, 50, train_loader,\\\n",
    "                          val_loader, test_loader, scaler) \n",
    "        p_val = t_test([i.tolist() for i in full_mses],\\\n",
    "             [i.tolist() for i in full_mses_res],alternative='less')  \n",
    "        print(f\"\\tlength: {i}, p_val: {p_val}\")\n",
    "\n",
    "'''\n",
    "if __name__==\"__main__\":\n",
    "    #vary_alpha(1,5, type=\"e\", step=1)\n",
    "    #vary_alpha(3,4, type=\"e\", step=0.1)\n",
    "    #vary_alpha(3,3.1, type=\"e\", step=0.01) #3.05\n",
    "    \n",
    "    #vary_alpha(8,0.5,10)\n",
    "    vary_seq([4,6,8,10,12,14,16], z, p2, x_j, x_k)\n",
    "'''   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a75a557",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d151ec0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e281c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
