{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c2261f7",
   "metadata": {},
   "source": [
    "# Causality in multivariate time-series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370d14c9",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06eb48fc",
   "metadata": {},
   "source": [
    "## case a) test relationship between X_j and Y_k    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fe6f62",
   "metadata": {},
   "source": [
    "### generate data (synthetic datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b7ca017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>...</th>\n",
       "      <th>y3</th>\n",
       "      <th>y4</th>\n",
       "      <th>y5</th>\n",
       "      <th>y6</th>\n",
       "      <th>y7</th>\n",
       "      <th>y8</th>\n",
       "      <th>y9</th>\n",
       "      <th>y10</th>\n",
       "      <th>p</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.693071</td>\n",
       "      <td>0.749734</td>\n",
       "      <td>0.740559</td>\n",
       "      <td>0.730026</td>\n",
       "      <td>0.732499</td>\n",
       "      <td>0.738669</td>\n",
       "      <td>0.735497</td>\n",
       "      <td>0.745999</td>\n",
       "      <td>0.734189</td>\n",
       "      <td>0.705529</td>\n",
       "      <td>...</td>\n",
       "      <td>1.315905</td>\n",
       "      <td>1.608329</td>\n",
       "      <td>1.608329</td>\n",
       "      <td>1.608329</td>\n",
       "      <td>1.608329</td>\n",
       "      <td>1.107953</td>\n",
       "      <td>1.315905</td>\n",
       "      <td>1.608329</td>\n",
       "      <td>0.611221</td>\n",
       "      <td>0.768904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.753756</td>\n",
       "      <td>0.683741</td>\n",
       "      <td>0.746386</td>\n",
       "      <td>0.732608</td>\n",
       "      <td>0.722181</td>\n",
       "      <td>0.727579</td>\n",
       "      <td>0.743361</td>\n",
       "      <td>0.727185</td>\n",
       "      <td>0.672798</td>\n",
       "      <td>0.713996</td>\n",
       "      <td>...</td>\n",
       "      <td>1.608329</td>\n",
       "      <td>1.608329</td>\n",
       "      <td>1.265771</td>\n",
       "      <td>1.608329</td>\n",
       "      <td>1.608329</td>\n",
       "      <td>1.315905</td>\n",
       "      <td>1.272908</td>\n",
       "      <td>1.608329</td>\n",
       "      <td>0.387080</td>\n",
       "      <td>0.651297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.714920</td>\n",
       "      <td>0.722104</td>\n",
       "      <td>0.725951</td>\n",
       "      <td>0.683002</td>\n",
       "      <td>0.731724</td>\n",
       "      <td>0.724715</td>\n",
       "      <td>0.650578</td>\n",
       "      <td>0.722927</td>\n",
       "      <td>0.732833</td>\n",
       "      <td>...</td>\n",
       "      <td>1.550394</td>\n",
       "      <td>1.315905</td>\n",
       "      <td>1.555777</td>\n",
       "      <td>1.545866</td>\n",
       "      <td>1.315905</td>\n",
       "      <td>1.249525</td>\n",
       "      <td>1.315905</td>\n",
       "      <td>1.262108</td>\n",
       "      <td>0.301979</td>\n",
       "      <td>0.569107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.674211</td>\n",
       "      <td>0.738349</td>\n",
       "      <td>0.742453</td>\n",
       "      <td>0.661326</td>\n",
       "      <td>0.722351</td>\n",
       "      <td>0.680168</td>\n",
       "      <td>0.645651</td>\n",
       "      <td>0.643214</td>\n",
       "      <td>0.745941</td>\n",
       "      <td>0.669091</td>\n",
       "      <td>...</td>\n",
       "      <td>1.267359</td>\n",
       "      <td>1.249525</td>\n",
       "      <td>1.315905</td>\n",
       "      <td>1.555777</td>\n",
       "      <td>1.464042</td>\n",
       "      <td>1.232654</td>\n",
       "      <td>1.608329</td>\n",
       "      <td>1.194044</td>\n",
       "      <td>0.275765</td>\n",
       "      <td>0.502619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.619043</td>\n",
       "      <td>0.733141</td>\n",
       "      <td>0.626638</td>\n",
       "      <td>0.638662</td>\n",
       "      <td>0.732328</td>\n",
       "      <td>0.657389</td>\n",
       "      <td>0.670579</td>\n",
       "      <td>0.611343</td>\n",
       "      <td>0.634421</td>\n",
       "      <td>0.750288</td>\n",
       "      <td>...</td>\n",
       "      <td>1.425759</td>\n",
       "      <td>1.445328</td>\n",
       "      <td>1.608329</td>\n",
       "      <td>1.182366</td>\n",
       "      <td>1.495224</td>\n",
       "      <td>1.406410</td>\n",
       "      <td>1.182853</td>\n",
       "      <td>1.540518</td>\n",
       "      <td>0.260415</td>\n",
       "      <td>0.455732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.526421</td>\n",
       "      <td>0.516246</td>\n",
       "      <td>0.517053</td>\n",
       "      <td>0.521333</td>\n",
       "      <td>0.497070</td>\n",
       "      <td>0.520755</td>\n",
       "      <td>0.495462</td>\n",
       "      <td>0.519600</td>\n",
       "      <td>0.532664</td>\n",
       "      <td>0.523518</td>\n",
       "      <td>...</td>\n",
       "      <td>1.258561</td>\n",
       "      <td>1.025938</td>\n",
       "      <td>1.252965</td>\n",
       "      <td>1.256274</td>\n",
       "      <td>1.028352</td>\n",
       "      <td>1.028842</td>\n",
       "      <td>1.258007</td>\n",
       "      <td>1.026938</td>\n",
       "      <td>-0.022146</td>\n",
       "      <td>0.074694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.518454</td>\n",
       "      <td>0.515656</td>\n",
       "      <td>0.497186</td>\n",
       "      <td>0.519268</td>\n",
       "      <td>0.526580</td>\n",
       "      <td>0.520441</td>\n",
       "      <td>0.521268</td>\n",
       "      <td>0.518023</td>\n",
       "      <td>0.516870</td>\n",
       "      <td>0.522316</td>\n",
       "      <td>...</td>\n",
       "      <td>1.258925</td>\n",
       "      <td>1.029515</td>\n",
       "      <td>1.026879</td>\n",
       "      <td>1.256274</td>\n",
       "      <td>1.261713</td>\n",
       "      <td>1.261894</td>\n",
       "      <td>1.255684</td>\n",
       "      <td>1.033487</td>\n",
       "      <td>-0.006050</td>\n",
       "      <td>0.082098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.499914</td>\n",
       "      <td>0.505554</td>\n",
       "      <td>0.523240</td>\n",
       "      <td>0.510995</td>\n",
       "      <td>0.532502</td>\n",
       "      <td>0.510356</td>\n",
       "      <td>0.507178</td>\n",
       "      <td>0.534066</td>\n",
       "      <td>0.503130</td>\n",
       "      <td>0.526591</td>\n",
       "      <td>...</td>\n",
       "      <td>1.030268</td>\n",
       "      <td>1.260019</td>\n",
       "      <td>1.034851</td>\n",
       "      <td>1.259580</td>\n",
       "      <td>1.028929</td>\n",
       "      <td>1.263254</td>\n",
       "      <td>1.026763</td>\n",
       "      <td>1.258312</td>\n",
       "      <td>0.188805</td>\n",
       "      <td>0.083666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.509237</td>\n",
       "      <td>0.515571</td>\n",
       "      <td>0.519724</td>\n",
       "      <td>0.516923</td>\n",
       "      <td>0.530387</td>\n",
       "      <td>0.538423</td>\n",
       "      <td>0.512905</td>\n",
       "      <td>0.497650</td>\n",
       "      <td>0.523117</td>\n",
       "      <td>0.535129</td>\n",
       "      <td>...</td>\n",
       "      <td>1.031293</td>\n",
       "      <td>1.262669</td>\n",
       "      <td>1.033099</td>\n",
       "      <td>1.031215</td>\n",
       "      <td>1.033162</td>\n",
       "      <td>1.264005</td>\n",
       "      <td>1.031375</td>\n",
       "      <td>1.261298</td>\n",
       "      <td>0.079071</td>\n",
       "      <td>0.081430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.512648</td>\n",
       "      <td>0.512518</td>\n",
       "      <td>0.524941</td>\n",
       "      <td>0.513502</td>\n",
       "      <td>0.510722</td>\n",
       "      <td>0.519756</td>\n",
       "      <td>0.515128</td>\n",
       "      <td>0.530040</td>\n",
       "      <td>0.507805</td>\n",
       "      <td>0.527016</td>\n",
       "      <td>...</td>\n",
       "      <td>1.032687</td>\n",
       "      <td>1.033197</td>\n",
       "      <td>1.034928</td>\n",
       "      <td>1.267154</td>\n",
       "      <td>1.033162</td>\n",
       "      <td>1.028028</td>\n",
       "      <td>1.262354</td>\n",
       "      <td>1.031213</td>\n",
       "      <td>-0.036881</td>\n",
       "      <td>0.088152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           x1        x2        x3        x4        x5        x6        x7  \\\n",
       "0    0.693071  0.749734  0.740559  0.730026  0.732499  0.738669  0.735497   \n",
       "1    0.753756  0.683741  0.746386  0.732608  0.722181  0.727579  0.743361   \n",
       "2    0.718531  0.714920  0.722104  0.725951  0.683002  0.731724  0.724715   \n",
       "3    0.674211  0.738349  0.742453  0.661326  0.722351  0.680168  0.645651   \n",
       "4    0.619043  0.733141  0.626638  0.638662  0.732328  0.657389  0.670579   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "995  0.526421  0.516246  0.517053  0.521333  0.497070  0.520755  0.495462   \n",
       "996  0.518454  0.515656  0.497186  0.519268  0.526580  0.520441  0.521268   \n",
       "997  0.499914  0.505554  0.523240  0.510995  0.532502  0.510356  0.507178   \n",
       "998  0.509237  0.515571  0.519724  0.516923  0.530387  0.538423  0.512905   \n",
       "999  0.512648  0.512518  0.524941  0.513502  0.510722  0.519756  0.515128   \n",
       "\n",
       "           x8        x9       x10  ...        y3        y4        y5  \\\n",
       "0    0.745999  0.734189  0.705529  ...  1.315905  1.608329  1.608329   \n",
       "1    0.727185  0.672798  0.713996  ...  1.608329  1.608329  1.265771   \n",
       "2    0.650578  0.722927  0.732833  ...  1.550394  1.315905  1.555777   \n",
       "3    0.643214  0.745941  0.669091  ...  1.267359  1.249525  1.315905   \n",
       "4    0.611343  0.634421  0.750288  ...  1.425759  1.445328  1.608329   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "995  0.519600  0.532664  0.523518  ...  1.258561  1.025938  1.252965   \n",
       "996  0.518023  0.516870  0.522316  ...  1.258925  1.029515  1.026879   \n",
       "997  0.534066  0.503130  0.526591  ...  1.030268  1.260019  1.034851   \n",
       "998  0.497650  0.523117  0.535129  ...  1.031293  1.262669  1.033099   \n",
       "999  0.530040  0.507805  0.527016  ...  1.032687  1.033197  1.034928   \n",
       "\n",
       "           y6        y7        y8        y9       y10         p         z  \n",
       "0    1.608329  1.608329  1.107953  1.315905  1.608329  0.611221  0.768904  \n",
       "1    1.608329  1.608329  1.315905  1.272908  1.608329  0.387080  0.651297  \n",
       "2    1.545866  1.315905  1.249525  1.315905  1.262108  0.301979  0.569107  \n",
       "3    1.555777  1.464042  1.232654  1.608329  1.194044  0.275765  0.502619  \n",
       "4    1.182366  1.495224  1.406410  1.182853  1.540518  0.260415  0.455732  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "995  1.256274  1.028352  1.028842  1.258007  1.026938 -0.022146  0.074694  \n",
       "996  1.256274  1.261713  1.261894  1.255684  1.033487 -0.006050  0.082098  \n",
       "997  1.259580  1.028929  1.263254  1.026763  1.258312  0.188805  0.083666  \n",
       "998  1.031215  1.033162  1.264005  1.031375  1.261298  0.079071  0.081430  \n",
       "999  1.267154  1.033162  1.028028  1.262354  1.031213 -0.036881  0.088152  \n",
       "\n",
       "[1000 rows x 22 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "\n",
    "total_length=1000\n",
    "\n",
    "def sigmoid(x):\n",
    "        return 1 / (1 + math.exp(-x))\n",
    "    \n",
    "def generate(sig_to_noise): \n",
    "    np.random.seed(0)\n",
    "    z = [1,1,1,1]\n",
    "    x_arr = np.full((10,4),1.0)\n",
    "    y_arr = np.full((10,4),3.0)\n",
    "    x_arr_unini = np.full((10,total_length),0.0)\n",
    "    y_arr_unini = np.full((10,total_length),0.0)\n",
    "    x = np.hstack((x_arr, x_arr_unini))\n",
    "    y = np.hstack((y_arr, y_arr_unini)) \n",
    "    \n",
    "    p = []\n",
    "    n = [3,3,3,3]\n",
    "    t1 = [3,3,3,3]\n",
    "    \n",
    "    \n",
    "    for i in range(4,total_length+4):  #time\n",
    "        z.append(math.tanh(z[i-1]+np.random.normal(0,0.01)))\n",
    "        p.append(z[i]**2+np.random.normal(0,0.05))\n",
    "        \n",
    "        for j in range(0,10):\n",
    "            m = random.randint(1,5)  #random lag\n",
    "            n = random.randint(1,5)  #random lag\n",
    "            x[j][i] = sigmoid(z[i-m])+np.random.normal(0,0.01)\n",
    "            term1 = sigmoid(z[i-m])\n",
    "            term2 = sigmoid(x[j][i-n])\n",
    "            noise = np.random.normal(0,1)\n",
    "            alpha = (abs(term1+term2)/sig_to_noise)/abs(noise)\n",
    "            \n",
    "            y[j][i] = term1+term2+alpha*noise\n",
    "\n",
    "\n",
    "    x=x[:,-total_length:]    \n",
    "    y=y[:,-total_length:]\n",
    "    p=p[-total_length:]\n",
    "    z=z[-total_length:]\n",
    "    \n",
    "    #table format\n",
    "    df1=pd.DataFrame({\"x1\":x[0,:]})\n",
    "    for m in range(1,10):\n",
    "        df1.insert(loc=len(df1.columns), column='x'+str(m+1), value=x[m,:])\n",
    "    for m in range(0,10):\n",
    "        df1.insert(loc=len(df1.columns), column='y'+str(m+1), value=y[m,:])\n",
    "    df1.insert(loc=len(df1.columns), column='p', value=p)\n",
    "    df1.insert(loc=len(df1.columns), column='z', value=z)\n",
    "    return df1\n",
    "\n",
    "df1 = generate(10)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec60d2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(\"case_a.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ed1700",
   "metadata": {},
   "source": [
    "### method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8290d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from torch import optim\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import gruvae\n",
    "import train\n",
    "from data_loader import create_inout_sequences\n",
    "from functions import t_test\n",
    "from generate_data_a import generate\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"case_a.csv\")[:1000]\n",
    "\n",
    "k=random.randint(0, 9)\n",
    "l=random.randint(0, 9)\n",
    "\n",
    "x = data['x'+str(k+1)].tolist()\n",
    "y = data['y'+str(l+1)].tolist()\n",
    "z = data[\"z\"].tolist()\n",
    "p = data[\"p\"].tolist()\n",
    "\n",
    "\n",
    "  \n",
    "def obtain_errors(model,trials, train_loader,\\\n",
    "                  val_loader, test_loader, scaler, lam=0,\\\n",
    "                  model_type=\"full\", res=\"No\"):\n",
    "    torch.manual_seed(0)\n",
    "    mses = []\n",
    "    mses_nox = []\n",
    "    vae_trainer = train.AutoEncoderTrainer(model, optim.Adam,\\\n",
    "                    train_loader, val_loader,\\\n",
    "                    test_loader, scaler, 0.001, lam, model_type)\n",
    "    for i in range(trials):\n",
    "        _,mse,mse_nox,_ = vae_trainer.train_val_test_iter(test_loader,\\\n",
    "                                                          \"test\", res)\n",
    "        mses.append(mse)\n",
    "        mses_nox.append(mse_nox)\n",
    "    return mses,mses_nox\n",
    "\n",
    "\n",
    "def run_model(z, p, x, y, seq=20):\n",
    "    torch.manual_seed(0)\n",
    "    model=gruvae.GRUVAE(1,1,5,5,5,5,2,5,10,3,0.3)\n",
    "    train_loader, val_loader, test_loader, scaler\\\n",
    "        = create_inout_sequences(z, p, x, y, seq, 800, 100, 100, 10)\n",
    "    vae_trainer = train.AutoEncoderTrainer(model, optim.Adam,\\\n",
    "                            train_loader, val_loader,\\\n",
    "                            test_loader, scaler, lr=0.001, lam=0.01)\n",
    "    _,_,model = vae_trainer.train_and_evaluate(50)\n",
    "    return train_loader, val_loader, test_loader, model, scaler\n",
    "\n",
    "\n",
    "train_loader, val_loader, test_loader, model, scaler = run_model(z, p, x, y)\n",
    "full_mses, full_mses_res = obtain_errors(model, 50, train_loader,\\\n",
    "                          val_loader, test_loader, scaler)  \n",
    "        \n",
    "print(t_test([i.tolist() for i in full_mses],\\\n",
    "             [i.tolist() for i in full_mses_res],alternative='greater'))\n",
    "             \n",
    "def calc_pvalues(sig_to_noise_low=\"default\", sig_to_noise_upp=\"default\"):\n",
    "    \n",
    "    if sig_to_noise_low !=\"default\":\n",
    "        data_low = generate(sig_to_noise_low)\n",
    "        z_low = data_low[\"z\"].tolist()\n",
    "        p_low = data_low[\"p\"].tolist()\n",
    "        x_low = data_low[\"x\"].tolist()\n",
    "        y_low = data_low[\"y\"].tolist()\n",
    "        \n",
    "        train_loader, val_loader, test_loader, model, scaler\\\n",
    "            = run_model(z_low, p_low, x_low, y_low)\n",
    "        full_mses, full_mses_res = obtain_errors(model, 50, train_loader,\\\n",
    "            val_loader, test_loader, scaler)  \n",
    "        p_value_low = t_test([i.tolist() for i in full_mses],\\\n",
    "            [i.tolist() for i in full_mses_res],alternative='less')\n",
    "    \n",
    "    if sig_to_noise_upp !=\"default\":\n",
    "        data_upp = generate(sig_to_noise_upp)\n",
    "        z_upp = data_upp[\"z\"].tolist()\n",
    "        p_upp = data_upp[\"p\"].tolist()\n",
    "        x_upp = data_upp[\"x\"].tolist()\n",
    "        y_upp = data_upp[\"y\"].tolist()\n",
    "   \n",
    "        train_loader, val_loader, test_loader, model, scaler\\\n",
    "            = run_model(z_upp, p_upp, x_upp, y_upp)\n",
    "        full_mses, full_mses_res = obtain_errors(model, 50, train_loader,\\\n",
    "            val_loader, test_loader, scaler)  \n",
    "        p_value_upp = t_test([i.tolist() for i in full_mses],\\\n",
    "            [i.tolist() for i in full_mses_res],alternative='less')\n",
    "    \n",
    "    if  sig_to_noise_low!=\"default\" and sig_to_noise_upp!=\"default\":   \n",
    "        return p_value_low, p_value_upp\n",
    "    elif sig_to_noise_low!=\"default\" and sig_to_noise_upp==\"default\":\n",
    "        return p_value_low\n",
    "    elif sig_to_noise_upp!=\"default\" and sig_to_noise_low==\"default\":\n",
    "        return p_value_upp\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    \n",
    "def vary_alpha(trials, sig_to_noise_low, sig_to_noise_upp, type=\"bisection\",\\\n",
    "               step=0.1):\n",
    "    p_value_low, p_value_upp = calc_pvalues(sig_to_noise_low,sig_to_noise_upp)    \n",
    "    print(p_value_low, p_value_upp)\n",
    "    \n",
    "    if p_value_low<0.05 and p_value_upp<0.05:\n",
    "        print(\"enter new bounds\")\n",
    "        return None\n",
    "    elif p_value_low>0.05 and p_value_upp>0.05:\n",
    "        print(\"enter new bounds\")\n",
    "        return None\n",
    "    c=0\n",
    "    if type==\"bisection\":\n",
    "        prev_low = 0\n",
    "        prev_p = 0\n",
    "        for i in range(trials):\n",
    "            print(f\"\\tsig_to_noise_low: {sig_to_noise_low}, p_low: {p_value_low}, sig_to_noise_upp: {sig_to_noise_upp}, p_upp: {p_value_upp}\")            \n",
    "            prev_low = sig_to_noise_low\n",
    "            prev_p = p_value_low\n",
    "            if p_value_low>0.05:\n",
    "                sig_to_noise_low = (sig_to_noise_upp+sig_to_noise_low)/2\n",
    "                p_value_low = calc_pvalues(sig_to_noise_low=sig_to_noise_low)\n",
    "            if p_value_low<0.05:\n",
    "                sig_to_noise_upp = sig_to_noise_low\n",
    "                sig_to_noise_low = prev_low\n",
    "                p_value_upp = p_value_low\n",
    "                p_value_low = prev_p\n",
    "    else:\n",
    "        while c==0:\n",
    "            sig_to_noise_low+=step\n",
    "            p_value_low = calc_pvalues(sig_to_noise_low=sig_to_noise_low)\n",
    "            print(f\"\\tsig_to_noise_low: {sig_to_noise_low}, p_low: {p_value_low}, sig_to_noise_upp: {sig_to_noise_upp}, p_upp: {p_value_upp}\")\n",
    "            if p_value_low<0.05:       \n",
    "                break\n",
    "\n",
    "\n",
    "def vary_seq(seqs, z, p, x, y):\n",
    "    for i in seqs:\n",
    "        train_loader, val_loader, test_loader, model, scaler\\\n",
    "            = run_model(z, p, x, y, i)\n",
    "        full_mses, full_mses_res = obtain_errors(model, 50, train_loader,\\\n",
    "                          val_loader, test_loader, scaler) \n",
    "        p_val = t_test([i.tolist() for i in full_mses],\\\n",
    "             [i.tolist() for i in full_mses_res],alternative='less')  \n",
    "        print(f\"\\tlength: {i}, p_val: {p_val}\")\n",
    "\n",
    "'''\n",
    "if __name__==\"__main__\":\n",
    "    #vary_alpha(1,5, type=\"e\", step=1)\n",
    "    #vary_alpha(3,4, type=\"e\", step=0.1)\n",
    "    #vary_alpha(3,3.1, type=\"e\", step=0.01) #3.05\n",
    "    \n",
    "    #vary_alpha(8,0.5,10)\n",
    "    vary_seq([4,6,8,10,12,14,16], z, p, x, y)\n",
    "'''   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b31e130",
   "metadata": {},
   "source": [
    "### method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a627cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from torch import optim\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import gruvae\n",
    "import train\n",
    "from data_loader import create_inout_sequences\n",
    "from functions import t_test\n",
    "from generate_data_a import generate\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"case_a.csv\")[:1000]\n",
    "\n",
    "k=random.randint(0, 9)\n",
    "l=random.randint(0, 9)\n",
    "\n",
    "x = data['x'+str(k+1)].tolist()\n",
    "y = data['y'+str(l+1)].tolist()\n",
    "z = data[\"z\"].tolist()\n",
    "\n",
    "data = data.iloc[: , 1:]\n",
    "p1 = data[data.columns.difference(['x'+str(k+1), 'y'+str(l+1), \"z\"])].values.tolist()\n",
    "\n",
    "\n",
    "  \n",
    "def obtain_errors(model,trials, train_loader,\\\n",
    "                  val_loader, test_loader, scaler, lam=0,\\\n",
    "                  model_type=\"full\", res=\"No\"):\n",
    "    torch.manual_seed(0)\n",
    "    mses = []\n",
    "    mses_nox = []\n",
    "    vae_trainer = train.AutoEncoderTrainer(model, optim.Adam,\\\n",
    "                    train_loader, val_loader,\\\n",
    "                    test_loader, scaler, 0.001, lam, model_type)\n",
    "    for i in range(trials):\n",
    "        _,mse,mse_nox,_ = vae_trainer.train_val_test_iter(test_loader,\\\n",
    "                                                          \"test\", res)\n",
    "        mses.append(mse)\n",
    "        mses_nox.append(mse_nox)\n",
    "    return mses,mses_nox\n",
    "\n",
    "\n",
    "def run_model(z, p1, x, y, seq=20):\n",
    "    torch.manual_seed(0)\n",
    "    model=gruvae.GRUVAE(1,1,5,5,5,5,2,5,10,3,0.3)\n",
    "    train_loader, val_loader, test_loader, scaler\\\n",
    "        = create_inout_sequences(z, p1, x, y, seq, 800, 100, 100, 10)\n",
    "    vae_trainer = train.AutoEncoderTrainer(model, optim.Adam,\\\n",
    "                            train_loader, val_loader,\\\n",
    "                            test_loader, scaler, lr=0.001, lam=0.01)\n",
    "    _,_,model = vae_trainer.train_and_evaluate(50)\n",
    "    return train_loader, val_loader, test_loader, model, scaler\n",
    "\n",
    "\n",
    "train_loader, val_loader, test_loader, model, scaler = run_model(z, p1, x, y)\n",
    "full_mses, full_mses_res = obtain_errors(model, 50, train_loader,\\\n",
    "                          val_loader, test_loader, scaler)  \n",
    "        \n",
    "print(t_test([i.tolist() for i in full_mses],\\\n",
    "             [i.tolist() for i in full_mses_res],alternative='greater'))\n",
    "             \n",
    "def calc_pvalues(sig_to_noise_low=\"default\", sig_to_noise_upp=\"default\"):\n",
    "    \n",
    "    if sig_to_noise_low !=\"default\":\n",
    "        data_low = generate(sig_to_noise_low)\n",
    "        z_low = data_low[\"z\"].tolist()\n",
    "        p_low = data_low[\"p1\"].tolist()\n",
    "        x_low = data_low[\"x\"].tolist()\n",
    "        y_low = data_low[\"y\"].tolist()\n",
    "        \n",
    "        train_loader, val_loader, test_loader, model, scaler\\\n",
    "            = run_model(z_low, p_low, x_low, y_low)\n",
    "        full_mses, full_mses_res = obtain_errors(model, 50, train_loader,\\\n",
    "            val_loader, test_loader, scaler)  \n",
    "        p_value_low = t_test([i.tolist() for i in full_mses],\\\n",
    "            [i.tolist() for i in full_mses_res],alternative='less')\n",
    "    \n",
    "    if sig_to_noise_upp !=\"default\":\n",
    "        data_upp = generate(sig_to_noise_upp)\n",
    "        z_upp = data_upp[\"z\"].tolist()\n",
    "        p_upp = data_upp[\"p1\"].tolist()\n",
    "        x_upp = data_upp[\"x\"].tolist()\n",
    "        y_upp = data_upp[\"y\"].tolist()\n",
    "   \n",
    "        train_loader, val_loader, test_loader, model, scaler\\\n",
    "            = run_model(z_upp, p_upp, x_upp, y_upp)\n",
    "        full_mses, full_mses_res = obtain_errors(model, 50, train_loader,\\\n",
    "            val_loader, test_loader, scaler)  \n",
    "        p_value_upp = t_test([i.tolist() for i in full_mses],\\\n",
    "            [i.tolist() for i in full_mses_res],alternative='less')\n",
    "    \n",
    "    if  sig_to_noise_low!=\"default\" and sig_to_noise_upp!=\"default\":   \n",
    "        return p_value_low, p_value_upp\n",
    "    elif sig_to_noise_low!=\"default\" and sig_to_noise_upp==\"default\":\n",
    "        return p_value_low\n",
    "    elif sig_to_noise_upp!=\"default\" and sig_to_noise_low==\"default\":\n",
    "        return p_value_upp\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    \n",
    "def vary_alpha(trials, sig_to_noise_low, sig_to_noise_upp, type=\"bisection\",\\\n",
    "               step=0.1):\n",
    "    p_value_low, p_value_upp = calc_pvalues(sig_to_noise_low,sig_to_noise_upp)    \n",
    "    print(p_value_low, p_value_upp)\n",
    "    \n",
    "    if p_value_low<0.05 and p_value_upp<0.05:\n",
    "        print(\"enter new bounds\")\n",
    "        return None\n",
    "    elif p_value_low>0.05 and p_value_upp>0.05:\n",
    "        print(\"enter new bounds\")\n",
    "        return None\n",
    "    c=0\n",
    "    if type==\"bisection\":\n",
    "        prev_low = 0\n",
    "        prev_p = 0\n",
    "        for i in range(trials):\n",
    "            print(f\"\\tsig_to_noise_low: {sig_to_noise_low}, p_low: {p_value_low}, sig_to_noise_upp: {sig_to_noise_upp}, p_upp: {p_value_upp}\")            \n",
    "            prev_low = sig_to_noise_low\n",
    "            prev_p = p_value_low\n",
    "            if p_value_low>0.05:\n",
    "                sig_to_noise_low = (sig_to_noise_upp+sig_to_noise_low)/2\n",
    "                p_value_low = calc_pvalues(sig_to_noise_low=sig_to_noise_low)\n",
    "            if p_value_low<0.05:\n",
    "                sig_to_noise_upp = sig_to_noise_low\n",
    "                sig_to_noise_low = prev_low\n",
    "                p_value_upp = p_value_low\n",
    "                p_value_low = prev_p\n",
    "    else:\n",
    "        while c==0:\n",
    "            sig_to_noise_low+=step\n",
    "            p_value_low = calc_pvalues(sig_to_noise_low=sig_to_noise_low)\n",
    "            print(f\"\\tsig_to_noise_low: {sig_to_noise_low}, p_low: {p_value_low}, sig_to_noise_upp: {sig_to_noise_upp}, p_upp: {p_value_upp}\")\n",
    "            if p_value_low<0.05:       \n",
    "                break\n",
    "\n",
    "\n",
    "def vary_seq(seqs, z, p1, x, y):\n",
    "    for i in seqs:\n",
    "        train_loader, val_loader, test_loader, model, scaler\\\n",
    "            = run_model(z, p1, x, y, i)\n",
    "        full_mses, full_mses_res = obtain_errors(model, 50, train_loader,\\\n",
    "                          val_loader, test_loader, scaler) \n",
    "        p_val = t_test([i.tolist() for i in full_mses],\\\n",
    "             [i.tolist() for i in full_mses_res],alternative='less')  \n",
    "        print(f\"\\tlength: {i}, p_val: {p_val}\")\n",
    "\n",
    "'''\n",
    "if __name__==\"__main__\":\n",
    "    #vary_alpha(1,5, type=\"e\", step=1)\n",
    "    #vary_alpha(3,4, type=\"e\", step=0.1)\n",
    "    #vary_alpha(3,3.1, type=\"e\", step=0.01) #3.05\n",
    "    \n",
    "    #vary_alpha(8,0.5,10)\n",
    "    vary_seq([4,6,8,10,12,14,16], z, p1, x, y)\n",
    "'''   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c04e90",
   "metadata": {},
   "source": [
    "### method 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f996ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from torch import optim\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import pandas as pd  # to load the dataframe\n",
    "from sklearn.preprocessing import StandardScaler  # to standardize the features\n",
    "from sklearn.decomposition import PCA  # to apply PCA\n",
    "\n",
    "import gruvae\n",
    "import train\n",
    "from data_loader import create_inout_sequences\n",
    "from functions import t_test\n",
    "from generate_data_a import generate\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"case_a.csv\")[:1000]\n",
    "\n",
    "k=random.randint(0, 9)\n",
    "l=random.randint(0, 9)\n",
    "\n",
    "x = data['x'+str(k+1)].tolist()\n",
    "y = data['y'+str(l+1)].tolist()\n",
    "z = data[\"z\"].tolist()\n",
    "\n",
    "data = data.iloc[: , 1:]\n",
    "p1 = data[data.columns.difference(['x'+str(k+1), 'y'+str(l+1), \"z\"])]\n",
    "\n",
    "#PCA\n",
    "#convert the dataset into a pandas data frame\n",
    "df = pd.DataFrame(p1)\n",
    "\n",
    "#Standardize the features\n",
    "#Create an object of StandardScaler which is present in sklearn.preprocessing\n",
    "scalar = StandardScaler()\n",
    "scaled_data = pd.DataFrame(scalar.fit_transform(df), columns=df.columns) #scaling the data\n",
    "\n",
    "#Applying PCA\n",
    "#Taking no. of Principal Components as 1\n",
    "pca = PCA(n_components = 1)\n",
    "pca.fit(scaled_data)\n",
    "data_pca = pca.transform(scaled_data)\n",
    "data_pca = pd.DataFrame(data_pca,columns=['PC1'])\n",
    "p2 = data_pca['PC1'].tolist()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "def obtain_errors(model,trials, train_loader,\\\n",
    "                  val_loader, test_loader, scaler, lam=0,\\\n",
    "                  model_type=\"full\", res=\"No\"):\n",
    "    torch.manual_seed(0)\n",
    "    mses = []\n",
    "    mses_nox = []\n",
    "    vae_trainer = train.AutoEncoderTrainer(model, optim.Adam,\\\n",
    "                    train_loader, val_loader,\\\n",
    "                    test_loader, scaler, 0.001, lam, model_type)\n",
    "    for i in range(trials):\n",
    "        _,mse,mse_nox,_ = vae_trainer.train_val_test_iter(test_loader,\\\n",
    "                                                          \"test\", res)\n",
    "        mses.append(mse)\n",
    "        mses_nox.append(mse_nox)\n",
    "    return mses,mses_nox\n",
    "\n",
    "\n",
    "def run_model(z, p2, x, y, seq=20):\n",
    "    torch.manual_seed(0)\n",
    "    model=gruvae.GRUVAE(1,1,5,5,5,5,2,5,10,3,0.3)\n",
    "    train_loader, val_loader, test_loader, scaler\\\n",
    "        = create_inout_sequences(z, p2, x, y, seq, 800, 100, 100, 10)\n",
    "    vae_trainer = train.AutoEncoderTrainer(model, optim.Adam,\\\n",
    "                            train_loader, val_loader,\\\n",
    "                            test_loader, scaler, lr=0.001, lam=0.01)\n",
    "    _,_,model = vae_trainer.train_and_evaluate(50)\n",
    "    return train_loader, val_loader, test_loader, model, scaler\n",
    "\n",
    "\n",
    "train_loader, val_loader, test_loader, model, scaler = run_model(z, p2, x, y)\n",
    "full_mses, full_mses_res = obtain_errors(model, 50, train_loader,\\\n",
    "                          val_loader, test_loader, scaler)  \n",
    "        \n",
    "print(t_test([i.tolist() for i in full_mses],\\\n",
    "             [i.tolist() for i in full_mses_res],alternative='greater'))\n",
    "             \n",
    "def calc_pvalues(sig_to_noise_low=\"default\", sig_to_noise_upp=\"default\"):\n",
    "    \n",
    "    if sig_to_noise_low !=\"default\":\n",
    "        data_low = generate(sig_to_noise_low)\n",
    "        z_low = data_low[\"z\"].tolist()\n",
    "        p_low = data_low[\"p2\"].tolist()\n",
    "        x_low = data_low[\"x\"].tolist()\n",
    "        y_low = data_low[\"y\"].tolist()\n",
    "        \n",
    "        train_loader, val_loader, test_loader, model, scaler\\\n",
    "            = run_model(z_low, p_low, x_low, y_low)\n",
    "        full_mses, full_mses_res = obtain_errors(model, 50, train_loader,\\\n",
    "            val_loader, test_loader, scaler)  \n",
    "        p_value_low = t_test([i.tolist() for i in full_mses],\\\n",
    "            [i.tolist() for i in full_mses_res],alternative='less')\n",
    "    \n",
    "    if sig_to_noise_upp !=\"default\":\n",
    "        data_upp = generate(sig_to_noise_upp)\n",
    "        z_upp = data_upp[\"z\"].tolist()\n",
    "        p_upp = data_upp[\"p2\"].tolist()\n",
    "        x_upp = data_upp[\"x\"].tolist()\n",
    "        y_upp = data_upp[\"y\"].tolist()\n",
    "   \n",
    "        train_loader, val_loader, test_loader, model, scaler\\\n",
    "            = run_model(z_upp, p_upp, x_upp, y_upp)\n",
    "        full_mses, full_mses_res = obtain_errors(model, 50, train_loader,\\\n",
    "            val_loader, test_loader, scaler)  \n",
    "        p_value_upp = t_test([i.tolist() for i in full_mses],\\\n",
    "            [i.tolist() for i in full_mses_res],alternative='less')\n",
    "    \n",
    "    if  sig_to_noise_low!=\"default\" and sig_to_noise_upp!=\"default\":   \n",
    "        return p_value_low, p_value_upp\n",
    "    elif sig_to_noise_low!=\"default\" and sig_to_noise_upp==\"default\":\n",
    "        return p_value_low\n",
    "    elif sig_to_noise_upp!=\"default\" and sig_to_noise_low==\"default\":\n",
    "        return p_value_upp\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    \n",
    "def vary_alpha(trials, sig_to_noise_low, sig_to_noise_upp, type=\"bisection\",\\\n",
    "               step=0.1):\n",
    "    p_value_low, p_value_upp = calc_pvalues(sig_to_noise_low,sig_to_noise_upp)    \n",
    "    print(p_value_low, p_value_upp)\n",
    "    \n",
    "    if p_value_low<0.05 and p_value_upp<0.05:\n",
    "        print(\"enter new bounds\")\n",
    "        return None\n",
    "    elif p_value_low>0.05 and p_value_upp>0.05:\n",
    "        print(\"enter new bounds\")\n",
    "        return None\n",
    "    c=0\n",
    "    if type==\"bisection\":\n",
    "        prev_low = 0\n",
    "        prev_p = 0\n",
    "        for i in range(trials):\n",
    "            print(f\"\\tsig_to_noise_low: {sig_to_noise_low}, p_low: {p_value_low}, sig_to_noise_upp: {sig_to_noise_upp}, p_upp: {p_value_upp}\")            \n",
    "            prev_low = sig_to_noise_low\n",
    "            prev_p = p_value_low\n",
    "            if p_value_low>0.05:\n",
    "                sig_to_noise_low = (sig_to_noise_upp+sig_to_noise_low)/2\n",
    "                p_value_low = calc_pvalues(sig_to_noise_low=sig_to_noise_low)\n",
    "            if p_value_low<0.05:\n",
    "                sig_to_noise_upp = sig_to_noise_low\n",
    "                sig_to_noise_low = prev_low\n",
    "                p_value_upp = p_value_low\n",
    "                p_value_low = prev_p\n",
    "    else:\n",
    "        while c==0:\n",
    "            sig_to_noise_low+=step\n",
    "            p_value_low = calc_pvalues(sig_to_noise_low=sig_to_noise_low)\n",
    "            print(f\"\\tsig_to_noise_low: {sig_to_noise_low}, p_low: {p_value_low}, sig_to_noise_upp: {sig_to_noise_upp}, p_upp: {p_value_upp}\")\n",
    "            if p_value_low<0.05:       \n",
    "                break\n",
    "\n",
    "\n",
    "def vary_seq(seqs, z, p2, x, y):\n",
    "    for i in seqs:\n",
    "        train_loader, val_loader, test_loader, model, scaler\\\n",
    "            = run_model(z, p2, x, y, i)\n",
    "        full_mses, full_mses_res = obtain_errors(model, 50, train_loader,\\\n",
    "                          val_loader, test_loader, scaler) \n",
    "        p_val = t_test([i.tolist() for i in full_mses],\\\n",
    "             [i.tolist() for i in full_mses_res],alternative='less')  \n",
    "        print(f\"\\tlength: {i}, p_val: {p_val}\")\n",
    "\n",
    "'''\n",
    "if __name__==\"__main__\":\n",
    "    #vary_alpha(1,5, type=\"e\", step=1)\n",
    "    #vary_alpha(3,4, type=\"e\", step=0.1)\n",
    "    #vary_alpha(3,3.1, type=\"e\", step=0.01) #3.05\n",
    "    \n",
    "    #vary_alpha(8,0.5,10)\n",
    "    vary_seq([4,6,8,10,12,14,16], z, p2, x, y)\n",
    "'''   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e59456",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cc4de4",
   "metadata": {},
   "source": [
    "## case b) test relationship between X_j and X_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e562955d",
   "metadata": {},
   "source": [
    "### generate data (synthetic datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e2ffe5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>p</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.608329</td>\n",
       "      <td>1.354164</td>\n",
       "      <td>1.608329</td>\n",
       "      <td>1.315905</td>\n",
       "      <td>1.354164</td>\n",
       "      <td>1.107953</td>\n",
       "      <td>1.315905</td>\n",
       "      <td>1.354164</td>\n",
       "      <td>1.301612</td>\n",
       "      <td>1.354164</td>\n",
       "      <td>0.611221</td>\n",
       "      <td>0.768904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.608329</td>\n",
       "      <td>1.608329</td>\n",
       "      <td>1.671514</td>\n",
       "      <td>1.315905</td>\n",
       "      <td>1.631086</td>\n",
       "      <td>1.315905</td>\n",
       "      <td>1.367602</td>\n",
       "      <td>1.555777</td>\n",
       "      <td>1.608329</td>\n",
       "      <td>1.315905</td>\n",
       "      <td>0.429496</td>\n",
       "      <td>0.650701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.608329</td>\n",
       "      <td>1.315905</td>\n",
       "      <td>1.608329</td>\n",
       "      <td>1.555777</td>\n",
       "      <td>1.608329</td>\n",
       "      <td>1.608329</td>\n",
       "      <td>1.249404</td>\n",
       "      <td>1.249404</td>\n",
       "      <td>1.272908</td>\n",
       "      <td>1.608329</td>\n",
       "      <td>0.272099</td>\n",
       "      <td>0.587211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.357430</td>\n",
       "      <td>1.272908</td>\n",
       "      <td>1.236405</td>\n",
       "      <td>1.341313</td>\n",
       "      <td>1.367602</td>\n",
       "      <td>1.608329</td>\n",
       "      <td>1.328314</td>\n",
       "      <td>1.344138</td>\n",
       "      <td>1.364817</td>\n",
       "      <td>1.581288</td>\n",
       "      <td>0.348170</td>\n",
       "      <td>0.536704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.404401</td>\n",
       "      <td>1.618962</td>\n",
       "      <td>1.364817</td>\n",
       "      <td>1.367602</td>\n",
       "      <td>1.279446</td>\n",
       "      <td>1.521072</td>\n",
       "      <td>1.555777</td>\n",
       "      <td>1.498314</td>\n",
       "      <td>1.328808</td>\n",
       "      <td>1.277930</td>\n",
       "      <td>0.217977</td>\n",
       "      <td>0.478136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1.396280</td>\n",
       "      <td>1.104147</td>\n",
       "      <td>1.148784</td>\n",
       "      <td>1.105839</td>\n",
       "      <td>1.345006</td>\n",
       "      <td>1.111737</td>\n",
       "      <td>1.103410</td>\n",
       "      <td>1.141217</td>\n",
       "      <td>1.396280</td>\n",
       "      <td>1.405916</td>\n",
       "      <td>0.011240</td>\n",
       "      <td>-0.100488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1.348877</td>\n",
       "      <td>1.361154</td>\n",
       "      <td>1.353232</td>\n",
       "      <td>1.405952</td>\n",
       "      <td>1.398258</td>\n",
       "      <td>1.103218</td>\n",
       "      <td>1.141604</td>\n",
       "      <td>1.142386</td>\n",
       "      <td>1.391009</td>\n",
       "      <td>1.348613</td>\n",
       "      <td>-0.066545</td>\n",
       "      <td>-0.101959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1.391228</td>\n",
       "      <td>1.137854</td>\n",
       "      <td>1.142048</td>\n",
       "      <td>1.148087</td>\n",
       "      <td>1.360473</td>\n",
       "      <td>1.352925</td>\n",
       "      <td>1.144433</td>\n",
       "      <td>1.399007</td>\n",
       "      <td>1.359718</td>\n",
       "      <td>1.404487</td>\n",
       "      <td>-0.056218</td>\n",
       "      <td>-0.108295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1.148466</td>\n",
       "      <td>1.145256</td>\n",
       "      <td>1.140209</td>\n",
       "      <td>1.101261</td>\n",
       "      <td>1.151812</td>\n",
       "      <td>1.404010</td>\n",
       "      <td>1.110562</td>\n",
       "      <td>1.398614</td>\n",
       "      <td>1.397809</td>\n",
       "      <td>1.113050</td>\n",
       "      <td>0.107108</td>\n",
       "      <td>-0.116596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1.397809</td>\n",
       "      <td>1.352314</td>\n",
       "      <td>1.405490</td>\n",
       "      <td>1.403681</td>\n",
       "      <td>1.108365</td>\n",
       "      <td>1.143762</td>\n",
       "      <td>1.355325</td>\n",
       "      <td>1.103186</td>\n",
       "      <td>1.144918</td>\n",
       "      <td>1.394104</td>\n",
       "      <td>0.012406</td>\n",
       "      <td>-0.125639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           x1        x2        x3        x4        x5        x6        x7  \\\n",
       "0    1.608329  1.354164  1.608329  1.315905  1.354164  1.107953  1.315905   \n",
       "1    1.608329  1.608329  1.671514  1.315905  1.631086  1.315905  1.367602   \n",
       "2    1.608329  1.315905  1.608329  1.555777  1.608329  1.608329  1.249404   \n",
       "3    1.357430  1.272908  1.236405  1.341313  1.367602  1.608329  1.328314   \n",
       "4    1.404401  1.618962  1.364817  1.367602  1.279446  1.521072  1.555777   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "995  1.396280  1.104147  1.148784  1.105839  1.345006  1.111737  1.103410   \n",
       "996  1.348877  1.361154  1.353232  1.405952  1.398258  1.103218  1.141604   \n",
       "997  1.391228  1.137854  1.142048  1.148087  1.360473  1.352925  1.144433   \n",
       "998  1.148466  1.145256  1.140209  1.101261  1.151812  1.404010  1.110562   \n",
       "999  1.397809  1.352314  1.405490  1.403681  1.108365  1.143762  1.355325   \n",
       "\n",
       "           x8        x9       x10         p         z  \n",
       "0    1.354164  1.301612  1.354164  0.611221  0.768904  \n",
       "1    1.555777  1.608329  1.315905  0.429496  0.650701  \n",
       "2    1.249404  1.272908  1.608329  0.272099  0.587211  \n",
       "3    1.344138  1.364817  1.581288  0.348170  0.536704  \n",
       "4    1.498314  1.328808  1.277930  0.217977  0.478136  \n",
       "..        ...       ...       ...       ...       ...  \n",
       "995  1.141217  1.396280  1.405916  0.011240 -0.100488  \n",
       "996  1.142386  1.391009  1.348613 -0.066545 -0.101959  \n",
       "997  1.399007  1.359718  1.404487 -0.056218 -0.108295  \n",
       "998  1.398614  1.397809  1.113050  0.107108 -0.116596  \n",
       "999  1.103186  1.144918  1.394104  0.012406 -0.125639  \n",
       "\n",
       "[1000 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "\n",
    "total_length=1000\n",
    "\n",
    "def sigmoid(x):\n",
    "        return 1 / (1 + math.exp(-x))\n",
    "    \n",
    "def generate(sig_to_noise): \n",
    "    np.random.seed(0)\n",
    "    z = [1,1,1,1]\n",
    "    x_arr = np.full((10,4),1.0)\n",
    "    x_arr_unini = np.full((10,total_length),0.0)\n",
    "    x = np.hstack((x_arr, x_arr_unini))\n",
    "    \n",
    "    p = []\n",
    "    n = [3,3,3,3]\n",
    "    t1 = [3,3,3,3]\n",
    "    \n",
    "    \n",
    "    for i in range(4,total_length+4):   #time\n",
    "        z.append(math.tanh(z[i-1]+np.random.normal(0,0.01)))\n",
    "        p.append(z[i]**2+np.random.normal(0,0.05))\n",
    "        \n",
    "        for j in range(0,10):\n",
    "            k = random.randint(0,9)\n",
    "            m = random.randint(1,5)  #random lag\n",
    "            n = random.randint(1,5)  #random lag\n",
    "            term1 = sigmoid(z[i-m])\n",
    "            term2 = sigmoid(x[k][i-n])\n",
    "            noise = np.random.normal(0,1)\n",
    "            alpha = (abs(term1+term2)/sig_to_noise)/abs(noise)  \n",
    "                \n",
    "            x[j][i] = term1+term2+alpha*noise\n",
    "\n",
    "\n",
    "\n",
    "    x=x[:,-total_length:]    \n",
    "    p=p[-total_length:]\n",
    "    z=z[-total_length:]\n",
    "    \n",
    "     #table format\n",
    "    df2=pd.DataFrame({\"x1\":x[0,:]})\n",
    "    for m in range(1,10):\n",
    "        df2.insert(loc=len(df2.columns), column='x'+str(m+1), value=x[m,:])\n",
    "    \n",
    "    \n",
    "    df2.insert(loc=len(df2.columns), column='p', value=p)\n",
    "    df2.insert(loc=len(df2.columns), column='z', value=z)\n",
    "   \n",
    "    return df2\n",
    "\n",
    "\n",
    "df2=generate(10)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7cdd052",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(\"case_b.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b00102",
   "metadata": {},
   "source": [
    "### method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e262e4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from torch import optim\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import gruvae\n",
    "import train\n",
    "from data_loader import create_inout_sequences\n",
    "from functions import t_test\n",
    "from generate_data_b import generate\n",
    "\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"case_b.csv\")[:1000]\n",
    "\n",
    "\n",
    "m = random.randint(0, 9)\n",
    "x_j = data['x'+str(m+1)].tolist()\n",
    "\n",
    "numbers = list(range(0, 10))\n",
    "numbers.remove(m)\n",
    "l = random.choice(numbers)\n",
    "x_k = data['x'+str(l+1)].tolist()\n",
    "\n",
    "z = data[\"z\"].tolist()\n",
    "p = data[\"p\"].tolist()\n",
    "\n",
    "\n",
    "  \n",
    "def obtain_errors(model,trials, train_loader,\\\n",
    "                  val_loader, test_loader, scaler, lam=0,\\\n",
    "                  model_type=\"full\", res=\"No\"):\n",
    "    torch.manual_seed(0)\n",
    "    mses = []\n",
    "    mses_nox = []\n",
    "    vae_trainer = train.AutoEncoderTrainer(model, optim.Adam,\\\n",
    "                    train_loader, val_loader,\\\n",
    "                    test_loader, scaler, 0.001, lam, model_type)\n",
    "    for i in range(trials):\n",
    "        _,mse,mse_nox,_ = vae_trainer.train_val_test_iter(test_loader,\\\n",
    "                                                          \"test\", res)\n",
    "        mses.append(mse)\n",
    "        mses_nox.append(mse_nox)\n",
    "    return mses,mses_nox\n",
    "\n",
    "\n",
    "def run_model(z, p, x_j, x_k, seq=20):\n",
    "    torch.manual_seed(0)\n",
    "    model=gruvae.GRUVAE(1,1,5,5,5,5,2,5,10,3,0.3)\n",
    "    train_loader, val_loader, test_loader, scaler\\\n",
    "        = create_inout_sequences(z, p, x_j, x_k, seq, 800, 100, 100, 10)\n",
    "    vae_trainer = train.AutoEncoderTrainer(model, optim.Adam,\\\n",
    "                            train_loader, val_loader,\\\n",
    "                            test_loader, scaler, lr=0.001, lam=0.01)\n",
    "    _,_,model = vae_trainer.train_and_evaluate(50)\n",
    "    return train_loader, val_loader, test_loader, model, scaler\n",
    "\n",
    "\n",
    "train_loader, val_loader, test_loader, model, scaler = run_model(z, p, x_j, x_k)\n",
    "full_mses, full_mses_res = obtain_errors(model, 50, train_loader,\\\n",
    "                          val_loader, test_loader, scaler)  \n",
    "        \n",
    "print(t_test([i.tolist() for i in full_mses],\\\n",
    "             [i.tolist() for i in full_mses_res],alternative='greater'))\n",
    "             \n",
    "def calc_pvalues(sig_to_noise_low=\"default\", sig_to_noise_upp=\"default\"):\n",
    "    \n",
    "    if sig_to_noise_low !=\"default\":\n",
    "        data_low = generate(sig_to_noise_low)\n",
    "        z_low = data_low[\"z\"].tolist()\n",
    "        p_low = data_low[\"p\"].tolist()\n",
    "        x_low = data_low['x'+str(m+1)].tolist()\n",
    "        y_low = data_low['x'+str(l+1)].tolist()\n",
    "        \n",
    "        train_loader, val_loader, test_loader, model, scaler\\\n",
    "            = run_model(z_low, p_low, x_low, y_low)\n",
    "        full_mses, full_mses_res = obtain_errors(model, 50, train_loader,\\\n",
    "            val_loader, test_loader, scaler)  \n",
    "        p_value_low = t_test([i.tolist() for i in full_mses],\\\n",
    "            [i.tolist() for i in full_mses_res],alternative='less')\n",
    "    \n",
    "    if sig_to_noise_upp !=\"default\":\n",
    "        data_upp = generate(sig_to_noise_upp)\n",
    "        z_upp = data_upp[\"z\"].tolist()\n",
    "        p_upp = data_upp[\"p\"].tolist()\n",
    "        x_upp = data_upp['x'+str(m+1)].tolist()\n",
    "        y_upp = data_upp['x'+str(l+1)].tolist()\n",
    "   \n",
    "        train_loader, val_loader, test_loader, model, scaler\\\n",
    "            = run_model(z_upp, p_upp, x_upp, y_upp)\n",
    "        full_mses, full_mses_res = obtain_errors(model, 50, train_loader,\\\n",
    "            val_loader, test_loader, scaler)  \n",
    "        p_value_upp = t_test([i.tolist() for i in full_mses],\\\n",
    "            [i.tolist() for i in full_mses_res],alternative='less')\n",
    "    \n",
    "    if  sig_to_noise_low!=\"default\" and sig_to_noise_upp!=\"default\":   \n",
    "        return p_value_low, p_value_upp\n",
    "    elif sig_to_noise_low!=\"default\" and sig_to_noise_upp==\"default\":\n",
    "        return p_value_low\n",
    "    elif sig_to_noise_upp!=\"default\" and sig_to_noise_low==\"default\":\n",
    "        return p_value_upp\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    \n",
    "def vary_alpha(trials, sig_to_noise_low, sig_to_noise_upp, type=\"bisection\",\\\n",
    "               step=0.1):\n",
    "    p_value_low, p_value_upp = calc_pvalues(sig_to_noise_low,sig_to_noise_upp)    \n",
    "    print(p_value_low, p_value_upp)\n",
    "    \n",
    "    if p_value_low<0.05 and p_value_upp<0.05:\n",
    "        print(\"enter new bounds\")\n",
    "        return None\n",
    "    elif p_value_low>0.05 and p_value_upp>0.05:\n",
    "        print(\"enter new bounds\")\n",
    "        return None\n",
    "    c=0\n",
    "    if type==\"bisection\":\n",
    "        prev_low = 0\n",
    "        prev_p = 0\n",
    "        for i in range(trials):\n",
    "            print(f\"\\tsig_to_noise_low: {sig_to_noise_low}, p_low: {p_value_low}, sig_to_noise_upp: {sig_to_noise_upp}, p_upp: {p_value_upp}\")            \n",
    "            prev_low = sig_to_noise_low\n",
    "            prev_p = p_value_low\n",
    "            if p_value_low>0.05:\n",
    "                sig_to_noise_low = (sig_to_noise_upp+sig_to_noise_low)/2\n",
    "                p_value_low = calc_pvalues(sig_to_noise_low=sig_to_noise_low)\n",
    "            if p_value_low<0.05:\n",
    "                sig_to_noise_upp = sig_to_noise_low\n",
    "                sig_to_noise_low = prev_low\n",
    "                p_value_upp = p_value_low\n",
    "                p_value_low = prev_p\n",
    "    else:\n",
    "        while c==0:\n",
    "            sig_to_noise_low+=step\n",
    "            p_value_low = calc_pvalues(sig_to_noise_low=sig_to_noise_low)\n",
    "            print(f\"\\tsig_to_noise_low: {sig_to_noise_low}, p_low: {p_value_low}, sig_to_noise_upp: {sig_to_noise_upp}, p_upp: {p_value_upp}\")\n",
    "            if p_value_low<0.05:       \n",
    "                break\n",
    "\n",
    "\n",
    "def vary_seq(seqs, z, p, x_j, x_k):\n",
    "    for i in seqs:\n",
    "        train_loader, val_loader, test_loader, model, scaler\\\n",
    "            = run_model(z, p, x_j, x_k, i)\n",
    "        full_mses, full_mses_res = obtain_errors(model, 50, train_loader,\\\n",
    "                          val_loader, test_loader, scaler) \n",
    "        p_val = t_test([i.tolist() for i in full_mses],\\\n",
    "             [i.tolist() for i in full_mses_res],alternative='less')  \n",
    "        print(f\"\\tlength: {i}, p_val: {p_val}\")\n",
    "\n",
    "'''\n",
    "if __name__==\"__main__\":\n",
    "    #vary_alpha(1,5, type=\"e\", step=1)\n",
    "    #vary_alpha(3,4, type=\"e\", step=0.1)\n",
    "    #vary_alpha(3,3.1, type=\"e\", step=0.01) #3.05\n",
    "    \n",
    "    #vary_alpha(8,0.5,10)\n",
    "    vary_seq([4,6,8,10,12,14,16], z, p, x_j, x_k)\n",
    "'''   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8b2798",
   "metadata": {},
   "source": [
    "### method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe38991e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from torch import optim\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import gruvae\n",
    "import train\n",
    "from data_loader import create_inout_sequences\n",
    "from functions import t_test\n",
    "from generate_data_b import generate\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"case_b.csv\")[:1000]\n",
    "\n",
    "\n",
    "z = data[\"z\"].tolist()\n",
    "\n",
    "m = random.randint(0, 9)\n",
    "x_j = data['x'+str(m+1)].tolist()\n",
    "\n",
    "numbers = list(range(0, 10))\n",
    "numbers.remove(m)\n",
    "l = random.choice(numbers)\n",
    "x_k = data['x'+str(l+1)].tolist()\n",
    "\n",
    "data = data.iloc[: , 1:]\n",
    "p1 = data[data.columns.difference(['x'+str(m+1), 'y'+str(l+1), \"z\"])].values.tolist()\n",
    "\n",
    "\n",
    "  \n",
    "def obtain_errors(model,trials, train_loader,\\\n",
    "                  val_loader, test_loader, scaler, lam=0,\\\n",
    "                  model_type=\"full\", res=\"No\"):\n",
    "    torch.manual_seed(0)\n",
    "    mses = []\n",
    "    mses_nox = []\n",
    "    vae_trainer = train.AutoEncoderTrainer(model, optim.Adam,\\\n",
    "                    train_loader, val_loader,\\\n",
    "                    test_loader, scaler, 0.001, lam, model_type)\n",
    "    for i in range(trials):\n",
    "        _,mse,mse_nox,_ = vae_trainer.train_val_test_iter(test_loader,\\\n",
    "                                                          \"test\", res)\n",
    "        mses.append(mse)\n",
    "        mses_nox.append(mse_nox)\n",
    "    return mses,mses_nox\n",
    "\n",
    "\n",
    "def run_model(z, p1, x_j, x_k, seq=20):\n",
    "    torch.manual_seed(0)\n",
    "    model=gruvae.GRUVAE(1,1,5,5,5,5,2,5,10,3,0.3)\n",
    "    train_loader, val_loader, test_loader, scaler\\\n",
    "        = create_inout_sequences(z, p1, x_i, x_j, seq, 800, 100, 100, 10)\n",
    "    vae_trainer = train.AutoEncoderTrainer(model, optim.Adam,\\\n",
    "                            train_loader, val_loader,\\\n",
    "                            test_loader, scaler, lr=0.001, lam=0.01)\n",
    "    _,_,model = vae_trainer.train_and_evaluate(50)\n",
    "    return train_loader, val_loader, test_loader, model, scaler\n",
    "\n",
    "\n",
    "train_loader, val_loader, test_loader, model, scaler = run_model(z, p1, x_j, x_k)\n",
    "full_mses, full_mses_res = obtain_errors(model, 50, train_loader,\\\n",
    "                          val_loader, test_loader, scaler)  \n",
    "        \n",
    "print(t_test([i.tolist() for i in full_mses],\\\n",
    "             [i.tolist() for i in full_mses_res],alternative='greater'))\n",
    "             \n",
    "def calc_pvalues(sig_to_noise_low=\"default\", sig_to_noise_upp=\"default\"):\n",
    "    \n",
    "    if sig_to_noise_low !=\"default\":\n",
    "        data_low = generate(sig_to_noise_low)\n",
    "        z_low = data_low[\"z\"].tolist()\n",
    "        p_low = data_low[\"p1\"].tolist()\n",
    "        x_low = data_low['x'+str(m+1)].tolist()\n",
    "        y_low = data_low['x'+str(l+1)].tolist()\n",
    "        \n",
    "        train_loader, val_loader, test_loader, model, scaler\\\n",
    "            = run_model(z_low, p_low, x_low, y_low)\n",
    "        full_mses, full_mses_res = obtain_errors(model, 50, train_loader,\\\n",
    "            val_loader, test_loader, scaler)  \n",
    "        p_value_low = t_test([i.tolist() for i in full_mses],\\\n",
    "            [i.tolist() for i in full_mses_res],alternative='less')\n",
    "    \n",
    "    if sig_to_noise_upp !=\"default\":\n",
    "        data_upp = generate(sig_to_noise_upp)\n",
    "        z_upp = data_upp[\"z\"].tolist()\n",
    "        p_upp = data_upp[\"p1\"].tolist()\n",
    "        x_upp = data_upp['x'+str(m+1)].tolist()\n",
    "        y_upp = data_upp['x'+str(l+1)].tolist()\n",
    "   \n",
    "        train_loader, val_loader, test_loader, model, scaler\\\n",
    "            = run_model(z_upp, p_upp, x_upp, y_upp)\n",
    "        full_mses, full_mses_res = obtain_errors(model, 50, train_loader,\\\n",
    "            val_loader, test_loader, scaler)  \n",
    "        p_value_upp = t_test([i.tolist() for i in full_mses],\\\n",
    "            [i.tolist() for i in full_mses_res],alternative='less')\n",
    "    \n",
    "    if  sig_to_noise_low!=\"default\" and sig_to_noise_upp!=\"default\":   \n",
    "        return p_value_low, p_value_upp\n",
    "    elif sig_to_noise_low!=\"default\" and sig_to_noise_upp==\"default\":\n",
    "        return p_value_low\n",
    "    elif sig_to_noise_upp!=\"default\" and sig_to_noise_low==\"default\":\n",
    "        return p_value_upp\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    \n",
    "def vary_alpha(trials, sig_to_noise_low, sig_to_noise_upp, type=\"bisection\",\\\n",
    "               step=0.1):\n",
    "    p_value_low, p_value_upp = calc_pvalues(sig_to_noise_low,sig_to_noise_upp)    \n",
    "    print(p_value_low, p_value_upp)\n",
    "    \n",
    "    if p_value_low<0.05 and p_value_upp<0.05:\n",
    "        print(\"enter new bounds\")\n",
    "        return None\n",
    "    elif p_value_low>0.05 and p_value_upp>0.05:\n",
    "        print(\"enter new bounds\")\n",
    "        return None\n",
    "    c=0\n",
    "    if type==\"bisection\":\n",
    "        prev_low = 0\n",
    "        prev_p = 0\n",
    "        for i in range(trials):\n",
    "            print(f\"\\tsig_to_noise_low: {sig_to_noise_low}, p_low: {p_value_low}, sig_to_noise_upp: {sig_to_noise_upp}, p_upp: {p_value_upp}\")            \n",
    "            prev_low = sig_to_noise_low\n",
    "            prev_p = p_value_low\n",
    "            if p_value_low>0.05:\n",
    "                sig_to_noise_low = (sig_to_noise_upp+sig_to_noise_low)/2\n",
    "                p_value_low = calc_pvalues(sig_to_noise_low=sig_to_noise_low)\n",
    "            if p_value_low<0.05:\n",
    "                sig_to_noise_upp = sig_to_noise_low\n",
    "                sig_to_noise_low = prev_low\n",
    "                p_value_upp = p_value_low\n",
    "                p_value_low = prev_p\n",
    "    else:\n",
    "        while c==0:\n",
    "            sig_to_noise_low+=step\n",
    "            p_value_low = calc_pvalues(sig_to_noise_low=sig_to_noise_low)\n",
    "            print(f\"\\tsig_to_noise_low: {sig_to_noise_low}, p_low: {p_value_low}, sig_to_noise_upp: {sig_to_noise_upp}, p_upp: {p_value_upp}\")\n",
    "            if p_value_low<0.05:       \n",
    "                break\n",
    "\n",
    "\n",
    "def vary_seq(seqs, z, p1, x_j, x_k):\n",
    "    for i in seqs:\n",
    "        train_loader, val_loader, test_loader, model, scaler\\\n",
    "            = run_model(z, p1, x_j, x_k, i)\n",
    "        full_mses, full_mses_res = obtain_errors(model, 50, train_loader,\\\n",
    "                          val_loader, test_loader, scaler) \n",
    "        p_val = t_test([i.tolist() for i in full_mses],\\\n",
    "             [i.tolist() for i in full_mses_res],alternative='less')  \n",
    "        print(f\"\\tlength: {i}, p_val: {p_val}\")\n",
    "\n",
    "'''\n",
    "if __name__==\"__main__\":\n",
    "    #vary_alpha(1,5, type=\"e\", step=1)\n",
    "    #vary_alpha(3,4, type=\"e\", step=0.1)\n",
    "    #vary_alpha(3,3.1, type=\"e\", step=0.01) #3.05\n",
    "    \n",
    "    #vary_alpha(8,0.5,10)\n",
    "    vary_seq([4,6,8,10,12,14,16], z, p1, x_j, x_k)\n",
    "'''   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de3d1b6",
   "metadata": {},
   "source": [
    "### method 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30e9852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from torch import optim\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import pandas as pd  # to load the dataframe\n",
    "from sklearn.preprocessing import StandardScaler  # to standardize the features\n",
    "from sklearn.decomposition import PCA  # to apply PCA\n",
    "\n",
    "import gruvae\n",
    "import train\n",
    "from data_loader import create_inout_sequences\n",
    "from functions import t_test\n",
    "from generate_data_b import generate\n",
    "\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"case_b.csv\")[:1000]\n",
    "\n",
    "\n",
    "m = random.randint(0, 9)\n",
    "x_j = data['x'+str(m+1)].tolist()\n",
    "\n",
    "numbers = list(range(0, 10))\n",
    "numbers.remove(m)\n",
    "l = random.choice(numbers)\n",
    "x_k = data['x'+str(l+1)].tolist()\n",
    "\n",
    "z = data[\"z\"].tolist()\n",
    "\n",
    "data = data.iloc[: , 1:]\n",
    "p1 = data[data.columns.difference(['x'+str(m+1), 'x'+str(l+1), \"z\"])]\n",
    "\n",
    "#PCA\n",
    "\n",
    "#convert the dataset into a pandas data frame\n",
    "df = pd.DataFrame(p1)\n",
    "\n",
    "#Standardize the features\n",
    "#Create an object of StandardScaler which is present in sklearn.preprocessing\n",
    "scalar = StandardScaler()\n",
    "scaled_data = pd.DataFrame(scalar.fit_transform(df), columns=df.columns) #scaling the data\n",
    " \n",
    "#Applying PCA\n",
    "#Taking no. of Principal Components as 1\n",
    "pca = PCA(n_components = 1)\n",
    "pca.fit(scaled_data)\n",
    "data_pca = pca.transform(scaled_data)\n",
    "data_pca = pd.DataFrame(data_pca,columns=['PC1'])\n",
    "p2 = data_pca['PC1'].tolist()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "def obtain_errors(model,trials, train_loader,\\\n",
    "                  val_loader, test_loader, scaler, lam=0,\\\n",
    "                  model_type=\"full\", res=\"No\"):\n",
    "    torch.manual_seed(0)\n",
    "    mses = []\n",
    "    mses_nox = []\n",
    "    vae_trainer = train.AutoEncoderTrainer(model, optim.Adam,\\\n",
    "                    train_loader, val_loader,\\\n",
    "                    test_loader, scaler, 0.001, lam, model_type)\n",
    "    for i in range(trials):\n",
    "        _,mse,mse_nox,_ = vae_trainer.train_val_test_iter(test_loader,\\\n",
    "                                                          \"test\", res)\n",
    "        mses.append(mse)\n",
    "        mses_nox.append(mse_nox)\n",
    "    return mses,mses_nox\n",
    "\n",
    "\n",
    "def run_model(z, p2, x_j, x_k, seq=20):\n",
    "    torch.manual_seed(0)\n",
    "    model=gruvae.GRUVAE(1,1,5,5,5,5,2,5,10,3,0.3)\n",
    "    train_loader, val_loader, test_loader, scaler\\\n",
    "        = create_inout_sequences(z, p2, x_j, x_k, seq, 800, 100, 100, 10)\n",
    "    vae_trainer = train.AutoEncoderTrainer(model, optim.Adam,\\\n",
    "                            train_loader, val_loader,\\\n",
    "                            test_loader, scaler, lr=0.001, lam=0.01)\n",
    "    _,_,model = vae_trainer.train_and_evaluate(50)\n",
    "    return train_loader, val_loader, test_loader, model, scaler\n",
    "\n",
    "\n",
    "train_loader, val_loader, test_loader, model, scaler = run_model(z, p2, x_j, x_k)\n",
    "full_mses, full_mses_res = obtain_errors(model, 50, train_loader,\\\n",
    "                          val_loader, test_loader, scaler)  \n",
    "        \n",
    "print(t_test([i.tolist() for i in full_mses],\\\n",
    "             [i.tolist() for i in full_mses_res],alternative='greater'))\n",
    "             \n",
    "def calc_pvalues(sig_to_noise_low=\"default\", sig_to_noise_upp=\"default\"):\n",
    "    \n",
    "    if sig_to_noise_low !=\"default\":\n",
    "        data_low = generate(sig_to_noise_low)\n",
    "        z_low = data_low[\"z\"].tolist()\n",
    "        p_low = data_low[\"p2\"].tolist()\n",
    "        x_low = data_low['x'+str(m+1)].tolist()\n",
    "        y_low = data_low['x'+str(l+1)].tolist()\n",
    "        \n",
    "        train_loader, val_loader, test_loader, model, scaler\\\n",
    "            = run_model(z_low, p_low, x_low, y_low)\n",
    "        full_mses, full_mses_res = obtain_errors(model, 50, train_loader,\\\n",
    "            val_loader, test_loader, scaler)  \n",
    "        p_value_low = t_test([i.tolist() for i in full_mses],\\\n",
    "            [i.tolist() for i in full_mses_res],alternative='less')\n",
    "    \n",
    "    if sig_to_noise_upp !=\"default\":\n",
    "        data_upp = generate(sig_to_noise_upp)\n",
    "        z_upp = data_upp[\"z\"].tolist()\n",
    "        p_upp = data_upp[\"p2\"].tolist()\n",
    "        x_upp = data_upp['x'+str(m+1)].tolist()\n",
    "        y_upp = data_upp['x'+str(l+1)].tolist()\n",
    "   \n",
    "        train_loader, val_loader, test_loader, model, scaler\\\n",
    "            = run_model(z_upp, p_upp, x_upp, y_upp)\n",
    "        full_mses, full_mses_res = obtain_errors(model, 50, train_loader,\\\n",
    "            val_loader, test_loader, scaler)  \n",
    "        p_value_upp = t_test([i.tolist() for i in full_mses],\\\n",
    "            [i.tolist() for i in full_mses_res],alternative='less')\n",
    "    \n",
    "    if  sig_to_noise_low!=\"default\" and sig_to_noise_upp!=\"default\":   \n",
    "        return p_value_low, p_value_upp\n",
    "    elif sig_to_noise_low!=\"default\" and sig_to_noise_upp==\"default\":\n",
    "        return p_value_low\n",
    "    elif sig_to_noise_upp!=\"default\" and sig_to_noise_low==\"default\":\n",
    "        return p_value_upp\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    \n",
    "def vary_alpha(trials, sig_to_noise_low, sig_to_noise_upp, type=\"bisection\",\\\n",
    "               step=0.1):\n",
    "    p_value_low, p_value_upp = calc_pvalues(sig_to_noise_low,sig_to_noise_upp)    \n",
    "    print(p_value_low, p_value_upp)\n",
    "    \n",
    "    if p_value_low<0.05 and p_value_upp<0.05:\n",
    "        print(\"enter new bounds\")\n",
    "        return None\n",
    "    elif p_value_low>0.05 and p_value_upp>0.05:\n",
    "        print(\"enter new bounds\")\n",
    "        return None\n",
    "    c=0\n",
    "    if type==\"bisection\":\n",
    "        prev_low = 0\n",
    "        prev_p = 0\n",
    "        for i in range(trials):\n",
    "            print(f\"\\tsig_to_noise_low: {sig_to_noise_low}, p_low: {p_value_low}, sig_to_noise_upp: {sig_to_noise_upp}, p_upp: {p_value_upp}\")            \n",
    "            prev_low = sig_to_noise_low\n",
    "            prev_p = p_value_low\n",
    "            if p_value_low>0.05:\n",
    "                sig_to_noise_low = (sig_to_noise_upp+sig_to_noise_low)/2\n",
    "                p_value_low = calc_pvalues(sig_to_noise_low=sig_to_noise_low)\n",
    "            if p_value_low<0.05:\n",
    "                sig_to_noise_upp = sig_to_noise_low\n",
    "                sig_to_noise_low = prev_low\n",
    "                p_value_upp = p_value_low\n",
    "                p_value_low = prev_p\n",
    "    else:\n",
    "        while c==0:\n",
    "            sig_to_noise_low+=step\n",
    "            p_value_low = calc_pvalues(sig_to_noise_low=sig_to_noise_low)\n",
    "            print(f\"\\tsig_to_noise_low: {sig_to_noise_low}, p_low: {p_value_low}, sig_to_noise_upp: {sig_to_noise_upp}, p_upp: {p_value_upp}\")\n",
    "            if p_value_low<0.05:       \n",
    "                break\n",
    "\n",
    "\n",
    "def vary_seq(seqs, z, p2, x_j, x_k):\n",
    "    for i in seqs:\n",
    "        train_loader, val_loader, test_loader, model, scaler\\\n",
    "            = run_model(z, p2, x_j, x_k, i)\n",
    "        full_mses, full_mses_res = obtain_errors(model, 50, train_loader,\\\n",
    "                          val_loader, test_loader, scaler) \n",
    "        p_val = t_test([i.tolist() for i in full_mses],\\\n",
    "             [i.tolist() for i in full_mses_res],alternative='less')  \n",
    "        print(f\"\\tlength: {i}, p_val: {p_val}\")\n",
    "\n",
    "'''\n",
    "if __name__==\"__main__\":\n",
    "    #vary_alpha(1,5, type=\"e\", step=1)\n",
    "    #vary_alpha(3,4, type=\"e\", step=0.1)\n",
    "    #vary_alpha(3,3.1, type=\"e\", step=0.01) #3.05\n",
    "    \n",
    "    #vary_alpha(8,0.5,10)\n",
    "    vary_seq([4,6,8,10,12,14,16], z, p2, x_j, x_k)\n",
    "'''   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
